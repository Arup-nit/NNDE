{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raroog/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TrialSolution(tf.keras.models.Model):\n",
    "  def __init__(self, conditions, n_i, n_h, n_o=1, activation='sigmoid', equation_type='ODE'):\n",
    "    super(TrialSolution, self).__init__()\n",
    "    self.n_i = n_i\n",
    "    self.n_h = n_h\n",
    "    self.n_o = n_o\n",
    "    self.conditions = conditions\n",
    "    self.hidden_layer = tf.keras.layers.Dense(units=self.n_h, activation=activation)\n",
    "    self.output_layer = tf.keras.layers.Dense(units=self.n_o, activation='linear')\n",
    "  \n",
    "  def call(self, X):\n",
    "    with tf.GradientTape() as tape:\n",
    "      X = tf.convert_to_tensor(X)\n",
    "      response = self.hidden_layer(X)\n",
    "      response = self.output_layer(response)\n",
    "      X1 = tf.concat([tf.reshape(X[:,0], shape=(X.shape[0], 1)),\n",
    "                      tf.constant(1.0, dtype='float64', shape=(X.shape[0], 1))], axis=1)\n",
    "#       print(X1)\n",
    "      tape.watch(X1)\n",
    "      response1 = self.hidden_layer(X1)\n",
    "#       print(response1)\n",
    "      response1 = self.output_layer(response1)\n",
    "    der_resp1 = tape.gradient(response1, X1)\n",
    "#     print(der_resp1)\n",
    "    der_resp1 = tf.reshape(der_resp1[:,1], shape=(response.shape[0],1))\n",
    "#     print(der_resp1)\n",
    "    x = tf.reshape(X[:,0], shape=(response.shape[0],1))\n",
    "    y = tf.reshape(X[:,1], shape=(response.shape[0],1))\n",
    "    one = tf.constant(1., dtype='float64', shape=(response.shape[0],1))\n",
    "    two = tf.constant(2., dtype='float64', shape=(response.shape[0],1))\n",
    "    pi = tf.constant(np.pi, dtype='float64', shape=(response.shape[0],1))\n",
    "    response -= response1\n",
    "    response -= der_resp1\n",
    "#     print(response)\n",
    "    response *= x*(one-x)*y\n",
    "    response += y * two * tf.sin(pi * x)\n",
    "    \n",
    "#     print(response)\n",
    "#     boundary_value = tf.constant(0., dtype='float64', shape=(response.shape[0],1))\n",
    "    \n",
    "#     for condition in self.conditions:\n",
    "#       vanishing = tf.constant(1., dtype='float64', shape=(response.shape[0],1))\n",
    "#       temp_bc = 0\n",
    "#       if condition['type'] == 'dirichlet':\n",
    "#         temp_bc = tf.reshape(condition['function'](X), shape=(response.shape[0],1))           \n",
    "#         for vanisher in self.conditions:\n",
    "#           if vanisher['variable'] != condition['variable'] and vanisher['value'] != condition['value']:\n",
    "#             if vanisher['type'] == 'dirichlet':\n",
    "#               vanishing *= (X[:, vanisher['variable']]\n",
    "#                                         - tf.constant(vanisher['value'], dtype='float64', shape=(response.shape[0],1)))\n",
    "#             elif vanisher['type'] == 'neumann':\n",
    "#               vanishing *= (X[:, vanisher['variable']]\n",
    "#                                         - tf.constant(vanisher['value'], dtype='float64', shape=(response.shape[0],1)))\n",
    "#         boundary_value += temp_bc * vanishing\n",
    "#         response *= (tf.constant(condition['value'], dtype='float64', shape=(response.shape[0],1))\n",
    "#                      - tf.reshape(X[:, condition['variable']], shape=(response.shape[0],1)))\n",
    "#       elif condition['type'] == 'neumann':\n",
    "#         temp_bc = (tf.reshape(condition['function'](X), shape=(response.shape[0],1))\n",
    "#                    * tf.reshape(X[:, condition['variable']], shape=(response.shape[0],1)))\n",
    "#         boundary_value = temp_bc\n",
    "#         response *= (tf.constant(condition['value'], dtype='float64', shape=(response.shape[0],1))\n",
    "#                      - tf.reshape(X[:, condition['variable']], shape=(response.shape[0],1)))  \n",
    "#     response += boundary_value\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bcs = [{'variable':0, 'value':0, 'type':'dirichlet',\n",
    "        'function':lambda X: X[:,1]**3},\n",
    "        {'variable':0, 'value':0, 'type':'dirichlet',\n",
    "        'function':lambda X: (tf.constant(1., dtype='float64', shape=(X.shape[0],1))+ X[:,1]**3)*tf.exp(tf.constant(-1., dtype='float64', shape=(X.shape[0],1)))},\n",
    "        {'variable':1, 'value':0, 'type':'dirichlet',\n",
    "        'function':lambda X: X[:,0]*tf.exp(-X[:,0])},\n",
    "        {'variable':1, 'value':1, 'type':'dirichlet',\n",
    "        'function':lambda X: (X[:,0]+tf.constant(1., dtype='float64', shape=(X.shape[0],1)))*tf.exp(-X[:,0])}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_samples = 10\n",
    "X_p = np.linspace(0, 1, n_samples)\n",
    "Y_p = np.linspace(0, 1, n_samples)\n",
    "X_p, Y_p = np.meshgrid(X_p, Y_p)\n",
    "X_p = X_p.flatten()\n",
    "Y_p = Y_p.flatten()\n",
    "samples = np.array([X_p, Y_p]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ts = TrialSolution(conditions=bcs, n_i=2, n_h=10, n_o=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def diff_loss(network, inputs):\n",
    "  with tf.GradientTape() as tape2:\n",
    "    with tf.GradientTape() as tape:\n",
    "      inputs = tf.convert_to_tensor(inputs)\n",
    "      tape.watch(inputs)\n",
    "      tape2.watch(inputs)\n",
    "      response = network(inputs)  \n",
    "    grads = tape.gradient(response, inputs)\n",
    "  laplace = tape2.gradient(grads, inputs)\n",
    "#   print(grads)\n",
    "#   print(laplace)\n",
    "  two = tf.constant(2, dtype='float64')\n",
    "  pi = tf.constant(np.pi, dtype='float64')\n",
    "  loss = tf.square(laplace[:,0] + laplace[:,1] + response * grads[:,1]\n",
    "                   - tf.sin(pi*inputs[:,0])*(two  - pi**2*inputs[:,1]**2 + two * inputs[:,1]**3*tf.sin(pi*inputs[:,0])))\n",
    "  return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.1)\n",
    "train_loss = tf.keras.metrics.Mean('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(X):\n",
    "  with tf.GradientTape() as tape:\n",
    "    loss = diff_loss(ts, X)\n",
    "  gradients = tape.gradient(loss, ts.trainable_variables)\n",
    "  optimizer.apply_gradients(zip(gradients, ts.trainable_variables))\n",
    "  train_loss(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0421 07:22:45.115151 140275149072128 tf_logging.py:161] Entity <bound method TrialSolution.call of <tensorflow.python.eager.function.TfMethodTarget object at 0x7f9403f710b8>> could not be transformed and will be staged without change. Error details can be found in the logs when running with the env variable AUTOGRAPH_VERBOSITY >= 1. Please report this to the AutoGraph team. Cause: Unexpected error transforming <bound method TrialSolution.call of <tensorflow.python.eager.function.TfMethodTarget object at 0x7f9403f710b8>>. If you believe this is due to a bug, please set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output when filing the bug report. Caused by: Failed to parse source code of <bound method TrialSolution.call of <tensorflow.python.eager.function.TfMethodTarget object at 0x7f9403f710b8>>, which Python reported as:\n",
      "  @tf.function\n",
      "  def call(self, X):\n",
      "    with tf.GradientTape() as tape:\n",
      "      X = tf.convert_to_tensor(X)\n",
      "      response = self.hidden_layer(X)\n",
      "      response = self.output_layer(response)\n",
      "      X1 = tf.concat([tf.reshape(X[:,0], shape=(X.shape[0], 1)),\n",
      "                      tf.constant(1.0, dtype='float64', shape=(X.shape[0], 1))], axis=1)\n",
      "#       print(X1)\n",
      "      tape.watch(X1)\n",
      "      response1 = self.hidden_layer(X1)\n",
      "#       print(response1)\n",
      "      response1 = self.output_layer(response1)\n",
      "    der_resp1 = tape.gradient(response1, X1)\n",
      "#     print(der_resp1)\n",
      "    der_resp1 = tf.reshape(der_resp1[:,1], shape=(response.shape[0],1))\n",
      "#     print(der_resp1)\n",
      "    x = tf.reshape(X[:,0], shape=(response.shape[0],1))\n",
      "    y = tf.reshape(X[:,1], shape=(response.shape[0],1))\n",
      "    one = tf.constant(1., dtype='float64', shape=(response.shape[0],1))\n",
      "    two = tf.constant(2., dtype='float64', shape=(response.shape[0],1))\n",
      "    pi = tf.constant(np.pi, dtype='float64', shape=(response.shape[0],1))\n",
      "    response -= response1\n",
      "    response -= der_resp1\n",
      "#     print(response)\n",
      "    response *= x*(one-x)*y\n",
      "    response += y * two * tf.sin(pi * x)\n",
      "\n",
      "#     print(response)\n",
      "#     boundary_value = tf.constant(0., dtype='float64', shape=(response.shape[0],1))\n",
      "\n",
      "#     for condition in self.conditions:\n",
      "#       vanishing = tf.constant(1., dtype='float64', shape=(response.shape[0],1))\n",
      "#       temp_bc = 0\n",
      "#       if condition['type'] == 'dirichlet':\n",
      "#         temp_bc = tf.reshape(condition['function'](X), shape=(response.shape[0],1))           \n",
      "#         for vanisher in self.conditions:\n",
      "#           if vanisher['variable'] != condition['variable'] and vanisher['value'] != condition['value']:\n",
      "#             if vanisher['type'] == 'dirichlet':\n",
      "#               vanishing *= (X[:, vanisher['variable']]\n",
      "#                                         - tf.constant(vanisher['value'], dtype='float64', shape=(response.shape[0],1)))\n",
      "#             elif vanisher['type'] == 'neumann':\n",
      "#               vanishing *= (X[:, vanisher['variable']]\n",
      "#                                         - tf.constant(vanisher['value'], dtype='float64', shape=(response.shape[0],1)))\n",
      "#         boundary_value += temp_bc * vanishing\n",
      "#         response *= (tf.constant(condition['value'], dtype='float64', shape=(response.shape[0],1))\n",
      "#                      - tf.reshape(X[:, condition['variable']], shape=(response.shape[0],1)))\n",
      "#       elif condition['type'] == 'neumann':\n",
      "#         temp_bc = (tf.reshape(condition['function'](X), shape=(response.shape[0],1))\n",
      "#                    * tf.reshape(X[:, condition['variable']], shape=(response.shape[0],1)))\n",
      "#         boundary_value = temp_bc\n",
      "#         response *= (tf.constant(condition['value'], dtype='float64', shape=(response.shape[0],1))\n",
      "#                      - tf.reshape(X[:, condition['variable']], shape=(response.shape[0],1)))  \n",
      "#     response += boundary_value\n",
      "    return response\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method TrialSolution.call of <tensorflow.python.eager.function.TfMethodTarget object at 0x7f9403f710b8>> could not be transformed and will be staged without change. Error details can be found in the logs when running with the env variable AUTOGRAPH_VERBOSITY >= 1. Please report this to the AutoGraph team. Cause: Unexpected error transforming <bound method TrialSolution.call of <tensorflow.python.eager.function.TfMethodTarget object at 0x7f9403f710b8>>. If you believe this is due to a bug, please set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output when filing the bug report. Caused by: Failed to parse source code of <bound method TrialSolution.call of <tensorflow.python.eager.function.TfMethodTarget object at 0x7f9403f710b8>>, which Python reported as:\n",
      "  @tf.function\n",
      "  def call(self, X):\n",
      "    with tf.GradientTape() as tape:\n",
      "      X = tf.convert_to_tensor(X)\n",
      "      response = self.hidden_layer(X)\n",
      "      response = self.output_layer(response)\n",
      "      X1 = tf.concat([tf.reshape(X[:,0], shape=(X.shape[0], 1)),\n",
      "                      tf.constant(1.0, dtype='float64', shape=(X.shape[0], 1))], axis=1)\n",
      "#       print(X1)\n",
      "      tape.watch(X1)\n",
      "      response1 = self.hidden_layer(X1)\n",
      "#       print(response1)\n",
      "      response1 = self.output_layer(response1)\n",
      "    der_resp1 = tape.gradient(response1, X1)\n",
      "#     print(der_resp1)\n",
      "    der_resp1 = tf.reshape(der_resp1[:,1], shape=(response.shape[0],1))\n",
      "#     print(der_resp1)\n",
      "    x = tf.reshape(X[:,0], shape=(response.shape[0],1))\n",
      "    y = tf.reshape(X[:,1], shape=(response.shape[0],1))\n",
      "    one = tf.constant(1., dtype='float64', shape=(response.shape[0],1))\n",
      "    two = tf.constant(2., dtype='float64', shape=(response.shape[0],1))\n",
      "    pi = tf.constant(np.pi, dtype='float64', shape=(response.shape[0],1))\n",
      "    response -= response1\n",
      "    response -= der_resp1\n",
      "#     print(response)\n",
      "    response *= x*(one-x)*y\n",
      "    response += y * two * tf.sin(pi * x)\n",
      "\n",
      "#     print(response)\n",
      "#     boundary_value = tf.constant(0., dtype='float64', shape=(response.shape[0],1))\n",
      "\n",
      "#     for condition in self.conditions:\n",
      "#       vanishing = tf.constant(1., dtype='float64', shape=(response.shape[0],1))\n",
      "#       temp_bc = 0\n",
      "#       if condition['type'] == 'dirichlet':\n",
      "#         temp_bc = tf.reshape(condition['function'](X), shape=(response.shape[0],1))           \n",
      "#         for vanisher in self.conditions:\n",
      "#           if vanisher['variable'] != condition['variable'] and vanisher['value'] != condition['value']:\n",
      "#             if vanisher['type'] == 'dirichlet':\n",
      "#               vanishing *= (X[:, vanisher['variable']]\n",
      "#                                         - tf.constant(vanisher['value'], dtype='float64', shape=(response.shape[0],1)))\n",
      "#             elif vanisher['type'] == 'neumann':\n",
      "#               vanishing *= (X[:, vanisher['variable']]\n",
      "#                                         - tf.constant(vanisher['value'], dtype='float64', shape=(response.shape[0],1)))\n",
      "#         boundary_value += temp_bc * vanishing\n",
      "#         response *= (tf.constant(condition['value'], dtype='float64', shape=(response.shape[0],1))\n",
      "#                      - tf.reshape(X[:, condition['variable']], shape=(response.shape[0],1)))\n",
      "#       elif condition['type'] == 'neumann':\n",
      "#         temp_bc = (tf.reshape(condition['function'](X), shape=(response.shape[0],1))\n",
      "#                    * tf.reshape(X[:, condition['variable']], shape=(response.shape[0],1)))\n",
      "#         boundary_value = temp_bc\n",
      "#         response *= (tf.constant(condition['value'], dtype='float64', shape=(response.shape[0],1))\n",
      "#                      - tf.reshape(X[:, condition['variable']], shape=(response.shape[0],1)))  \n",
      "#     response += boundary_value\n",
      "    return response\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0421 07:22:45.463173 140275149072128 tf_logging.py:161] Entity <bound method TrialSolution.call of <tensorflow.python.eager.function.TfMethodTarget object at 0x7f9403f710b8>> could not be transformed and will be staged without change. Error details can be found in the logs when running with the env variable AUTOGRAPH_VERBOSITY >= 1. Please report this to the AutoGraph team. Cause: Unexpected error transforming <bound method TrialSolution.call of <tensorflow.python.eager.function.TfMethodTarget object at 0x7f9403f710b8>>. If you believe this is due to a bug, please set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output when filing the bug report. Caused by: Failed to parse source code of <bound method TrialSolution.call of <tensorflow.python.eager.function.TfMethodTarget object at 0x7f9403f710b8>>, which Python reported as:\n",
      "  @tf.function\n",
      "  def call(self, X):\n",
      "    with tf.GradientTape() as tape:\n",
      "      X = tf.convert_to_tensor(X)\n",
      "      response = self.hidden_layer(X)\n",
      "      response = self.output_layer(response)\n",
      "      X1 = tf.concat([tf.reshape(X[:,0], shape=(X.shape[0], 1)),\n",
      "                      tf.constant(1.0, dtype='float64', shape=(X.shape[0], 1))], axis=1)\n",
      "#       print(X1)\n",
      "      tape.watch(X1)\n",
      "      response1 = self.hidden_layer(X1)\n",
      "#       print(response1)\n",
      "      response1 = self.output_layer(response1)\n",
      "    der_resp1 = tape.gradient(response1, X1)\n",
      "#     print(der_resp1)\n",
      "    der_resp1 = tf.reshape(der_resp1[:,1], shape=(response.shape[0],1))\n",
      "#     print(der_resp1)\n",
      "    x = tf.reshape(X[:,0], shape=(response.shape[0],1))\n",
      "    y = tf.reshape(X[:,1], shape=(response.shape[0],1))\n",
      "    one = tf.constant(1., dtype='float64', shape=(response.shape[0],1))\n",
      "    two = tf.constant(2., dtype='float64', shape=(response.shape[0],1))\n",
      "    pi = tf.constant(np.pi, dtype='float64', shape=(response.shape[0],1))\n",
      "    response -= response1\n",
      "    response -= der_resp1\n",
      "#     print(response)\n",
      "    response *= x*(one-x)*y\n",
      "    response += y * two * tf.sin(pi * x)\n",
      "\n",
      "#     print(response)\n",
      "#     boundary_value = tf.constant(0., dtype='float64', shape=(response.shape[0],1))\n",
      "\n",
      "#     for condition in self.conditions:\n",
      "#       vanishing = tf.constant(1., dtype='float64', shape=(response.shape[0],1))\n",
      "#       temp_bc = 0\n",
      "#       if condition['type'] == 'dirichlet':\n",
      "#         temp_bc = tf.reshape(condition['function'](X), shape=(response.shape[0],1))           \n",
      "#         for vanisher in self.conditions:\n",
      "#           if vanisher['variable'] != condition['variable'] and vanisher['value'] != condition['value']:\n",
      "#             if vanisher['type'] == 'dirichlet':\n",
      "#               vanishing *= (X[:, vanisher['variable']]\n",
      "#                                         - tf.constant(vanisher['value'], dtype='float64', shape=(response.shape[0],1)))\n",
      "#             elif vanisher['type'] == 'neumann':\n",
      "#               vanishing *= (X[:, vanisher['variable']]\n",
      "#                                         - tf.constant(vanisher['value'], dtype='float64', shape=(response.shape[0],1)))\n",
      "#         boundary_value += temp_bc * vanishing\n",
      "#         response *= (tf.constant(condition['value'], dtype='float64', shape=(response.shape[0],1))\n",
      "#                      - tf.reshape(X[:, condition['variable']], shape=(response.shape[0],1)))\n",
      "#       elif condition['type'] == 'neumann':\n",
      "#         temp_bc = (tf.reshape(condition['function'](X), shape=(response.shape[0],1))\n",
      "#                    * tf.reshape(X[:, condition['variable']], shape=(response.shape[0],1)))\n",
      "#         boundary_value = temp_bc\n",
      "#         response *= (tf.constant(condition['value'], dtype='float64', shape=(response.shape[0],1))\n",
      "#                      - tf.reshape(X[:, condition['variable']], shape=(response.shape[0],1)))  \n",
      "#     response += boundary_value\n",
      "    return response\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method TrialSolution.call of <tensorflow.python.eager.function.TfMethodTarget object at 0x7f9403f710b8>> could not be transformed and will be staged without change. Error details can be found in the logs when running with the env variable AUTOGRAPH_VERBOSITY >= 1. Please report this to the AutoGraph team. Cause: Unexpected error transforming <bound method TrialSolution.call of <tensorflow.python.eager.function.TfMethodTarget object at 0x7f9403f710b8>>. If you believe this is due to a bug, please set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output when filing the bug report. Caused by: Failed to parse source code of <bound method TrialSolution.call of <tensorflow.python.eager.function.TfMethodTarget object at 0x7f9403f710b8>>, which Python reported as:\n",
      "  @tf.function\n",
      "  def call(self, X):\n",
      "    with tf.GradientTape() as tape:\n",
      "      X = tf.convert_to_tensor(X)\n",
      "      response = self.hidden_layer(X)\n",
      "      response = self.output_layer(response)\n",
      "      X1 = tf.concat([tf.reshape(X[:,0], shape=(X.shape[0], 1)),\n",
      "                      tf.constant(1.0, dtype='float64', shape=(X.shape[0], 1))], axis=1)\n",
      "#       print(X1)\n",
      "      tape.watch(X1)\n",
      "      response1 = self.hidden_layer(X1)\n",
      "#       print(response1)\n",
      "      response1 = self.output_layer(response1)\n",
      "    der_resp1 = tape.gradient(response1, X1)\n",
      "#     print(der_resp1)\n",
      "    der_resp1 = tf.reshape(der_resp1[:,1], shape=(response.shape[0],1))\n",
      "#     print(der_resp1)\n",
      "    x = tf.reshape(X[:,0], shape=(response.shape[0],1))\n",
      "    y = tf.reshape(X[:,1], shape=(response.shape[0],1))\n",
      "    one = tf.constant(1., dtype='float64', shape=(response.shape[0],1))\n",
      "    two = tf.constant(2., dtype='float64', shape=(response.shape[0],1))\n",
      "    pi = tf.constant(np.pi, dtype='float64', shape=(response.shape[0],1))\n",
      "    response -= response1\n",
      "    response -= der_resp1\n",
      "#     print(response)\n",
      "    response *= x*(one-x)*y\n",
      "    response += y * two * tf.sin(pi * x)\n",
      "\n",
      "#     print(response)\n",
      "#     boundary_value = tf.constant(0., dtype='float64', shape=(response.shape[0],1))\n",
      "\n",
      "#     for condition in self.conditions:\n",
      "#       vanishing = tf.constant(1., dtype='float64', shape=(response.shape[0],1))\n",
      "#       temp_bc = 0\n",
      "#       if condition['type'] == 'dirichlet':\n",
      "#         temp_bc = tf.reshape(condition['function'](X), shape=(response.shape[0],1))           \n",
      "#         for vanisher in self.conditions:\n",
      "#           if vanisher['variable'] != condition['variable'] and vanisher['value'] != condition['value']:\n",
      "#             if vanisher['type'] == 'dirichlet':\n",
      "#               vanishing *= (X[:, vanisher['variable']]\n",
      "#                                         - tf.constant(vanisher['value'], dtype='float64', shape=(response.shape[0],1)))\n",
      "#             elif vanisher['type'] == 'neumann':\n",
      "#               vanishing *= (X[:, vanisher['variable']]\n",
      "#                                         - tf.constant(vanisher['value'], dtype='float64', shape=(response.shape[0],1)))\n",
      "#         boundary_value += temp_bc * vanishing\n",
      "#         response *= (tf.constant(condition['value'], dtype='float64', shape=(response.shape[0],1))\n",
      "#                      - tf.reshape(X[:, condition['variable']], shape=(response.shape[0],1)))\n",
      "#       elif condition['type'] == 'neumann':\n",
      "#         temp_bc = (tf.reshape(condition['function'](X), shape=(response.shape[0],1))\n",
      "#                    * tf.reshape(X[:, condition['variable']], shape=(response.shape[0],1)))\n",
      "#         boundary_value = temp_bc\n",
      "#         response *= (tf.constant(condition['value'], dtype='float64', shape=(response.shape[0],1))\n",
      "#                      - tf.reshape(X[:, condition['variable']], shape=(response.shape[0],1)))  \n",
      "#     response += boundary_value\n",
      "    return response\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=303, shape=(100, 1), dtype=float64, numpy=\n",
       "array([[0.00000000e+00],\n",
       "       [0.00000000e+00],\n",
       "       [0.00000000e+00],\n",
       "       [0.00000000e+00],\n",
       "       [0.00000000e+00],\n",
       "       [0.00000000e+00],\n",
       "       [0.00000000e+00],\n",
       "       [0.00000000e+00],\n",
       "       [0.00000000e+00],\n",
       "       [0.00000000e+00],\n",
       "       [0.00000000e+00],\n",
       "       [7.41452428e-02],\n",
       "       [1.39591986e-01],\n",
       "       [1.88276713e-01],\n",
       "       [2.14214100e-01],\n",
       "       [2.14218746e-01],\n",
       "       [1.88289221e-01],\n",
       "       [1.39608107e-01],\n",
       "       [7.41580296e-02],\n",
       "       [2.72143733e-17],\n",
       "       [0.00000000e+00],\n",
       "       [1.48519173e-01],\n",
       "       [2.79584098e-01],\n",
       "       [3.77067813e-01],\n",
       "       [4.28999717e-01],\n",
       "       [4.29009029e-01],\n",
       "       [3.77092888e-01],\n",
       "       [2.79616423e-01],\n",
       "       [1.48544820e-01],\n",
       "       [5.44287466e-17],\n",
       "       [0.00000000e+00],\n",
       "       [2.23120609e-01],\n",
       "       [4.19974151e-01],\n",
       "       [5.66370339e-01],\n",
       "       [6.44353394e-01],\n",
       "       [6.44367232e-01],\n",
       "       [5.66407602e-01],\n",
       "       [4.20022195e-01],\n",
       "       [2.23158737e-01],\n",
       "       [8.16431199e-17],\n",
       "       [0.00000000e+00],\n",
       "       [2.97947644e-01],\n",
       "       [5.60758693e-01],\n",
       "       [7.56179708e-01],\n",
       "       [8.60269877e-01],\n",
       "       [8.60287937e-01],\n",
       "       [7.56228341e-01],\n",
       "       [5.60821408e-01],\n",
       "       [2.97997425e-01],\n",
       "       [1.08857493e-16],\n",
       "       [0.00000000e+00],\n",
       "       [3.72997669e-01],\n",
       "       [7.01933052e-01],\n",
       "       [9.46489771e-01],\n",
       "       [1.07674218e+00],\n",
       "       [1.07676400e+00],\n",
       "       [9.46548537e-01],\n",
       "       [7.02008842e-01],\n",
       "       [3.73057840e-01],\n",
       "       [1.36071867e-16],\n",
       "       [0.00000000e+00],\n",
       "       [4.48267404e-01],\n",
       "       [8.43491390e-01],\n",
       "       [1.13729289e+00],\n",
       "       [1.29376167e+00],\n",
       "       [1.29378664e+00],\n",
       "       [1.13736015e+00],\n",
       "       [8.43578140e-01],\n",
       "       [4.48336288e-01],\n",
       "       [1.63286240e-16],\n",
       "       [0.00000000e+00],\n",
       "       [5.23752944e-01],\n",
       "       [9.85426778e-01],\n",
       "       [1.32858004e+00],\n",
       "       [1.51131817e+00],\n",
       "       [1.51134554e+00],\n",
       "       [1.32865377e+00],\n",
       "       [9.85521883e-01],\n",
       "       [5.23828470e-01],\n",
       "       [1.90500613e-16],\n",
       "       [0.00000000e+00],\n",
       "       [5.99449793e-01],\n",
       "       [1.12773127e+00],\n",
       "       [1.52034090e+00],\n",
       "       [1.72940010e+00],\n",
       "       [1.72942900e+00],\n",
       "       [1.52041874e+00],\n",
       "       [1.12783168e+00],\n",
       "       [5.99529538e-01],\n",
       "       [2.17714987e-16],\n",
       "       [0.00000000e+00],\n",
       "       [6.75352926e-01],\n",
       "       [1.27039601e+00],\n",
       "       [1.71256398e+00],\n",
       "       [1.94799458e+00],\n",
       "       [1.94802401e+00],\n",
       "       [1.71264325e+00],\n",
       "       [1.27049827e+00],\n",
       "       [6.75434142e-01],\n",
       "       [2.44929360e-16]])>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts(tf.convert_to_tensor(samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0421 07:22:46.396430 140275149072128 tf_logging.py:161] Entity <bound method TrialSolution.call of <tensorflow.python.eager.function.TfMethodTarget object at 0x7f9403f710b8>> could not be transformed and will be staged without change. Error details can be found in the logs when running with the env variable AUTOGRAPH_VERBOSITY >= 1. Please report this to the AutoGraph team. Cause: Unexpected error transforming <bound method TrialSolution.call of <tensorflow.python.eager.function.TfMethodTarget object at 0x7f9403f710b8>>. If you believe this is due to a bug, please set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output when filing the bug report. Caused by: Failed to parse source code of <bound method TrialSolution.call of <tensorflow.python.eager.function.TfMethodTarget object at 0x7f9403f710b8>>, which Python reported as:\n",
      "  @tf.function\n",
      "  def call(self, X):\n",
      "    with tf.GradientTape() as tape:\n",
      "      X = tf.convert_to_tensor(X)\n",
      "      response = self.hidden_layer(X)\n",
      "      response = self.output_layer(response)\n",
      "      X1 = tf.concat([tf.reshape(X[:,0], shape=(X.shape[0], 1)),\n",
      "                      tf.constant(1.0, dtype='float64', shape=(X.shape[0], 1))], axis=1)\n",
      "#       print(X1)\n",
      "      tape.watch(X1)\n",
      "      response1 = self.hidden_layer(X1)\n",
      "#       print(response1)\n",
      "      response1 = self.output_layer(response1)\n",
      "    der_resp1 = tape.gradient(response1, X1)\n",
      "#     print(der_resp1)\n",
      "    der_resp1 = tf.reshape(der_resp1[:,1], shape=(response.shape[0],1))\n",
      "#     print(der_resp1)\n",
      "    x = tf.reshape(X[:,0], shape=(response.shape[0],1))\n",
      "    y = tf.reshape(X[:,1], shape=(response.shape[0],1))\n",
      "    one = tf.constant(1., dtype='float64', shape=(response.shape[0],1))\n",
      "    two = tf.constant(2., dtype='float64', shape=(response.shape[0],1))\n",
      "    pi = tf.constant(np.pi, dtype='float64', shape=(response.shape[0],1))\n",
      "    response -= response1\n",
      "    response -= der_resp1\n",
      "#     print(response)\n",
      "    response *= x*(one-x)*y\n",
      "    response += y * two * tf.sin(pi * x)\n",
      "\n",
      "#     print(response)\n",
      "#     boundary_value = tf.constant(0., dtype='float64', shape=(response.shape[0],1))\n",
      "\n",
      "#     for condition in self.conditions:\n",
      "#       vanishing = tf.constant(1., dtype='float64', shape=(response.shape[0],1))\n",
      "#       temp_bc = 0\n",
      "#       if condition['type'] == 'dirichlet':\n",
      "#         temp_bc = tf.reshape(condition['function'](X), shape=(response.shape[0],1))           \n",
      "#         for vanisher in self.conditions:\n",
      "#           if vanisher['variable'] != condition['variable'] and vanisher['value'] != condition['value']:\n",
      "#             if vanisher['type'] == 'dirichlet':\n",
      "#               vanishing *= (X[:, vanisher['variable']]\n",
      "#                                         - tf.constant(vanisher['value'], dtype='float64', shape=(response.shape[0],1)))\n",
      "#             elif vanisher['type'] == 'neumann':\n",
      "#               vanishing *= (X[:, vanisher['variable']]\n",
      "#                                         - tf.constant(vanisher['value'], dtype='float64', shape=(response.shape[0],1)))\n",
      "#         boundary_value += temp_bc * vanishing\n",
      "#         response *= (tf.constant(condition['value'], dtype='float64', shape=(response.shape[0],1))\n",
      "#                      - tf.reshape(X[:, condition['variable']], shape=(response.shape[0],1)))\n",
      "#       elif condition['type'] == 'neumann':\n",
      "#         temp_bc = (tf.reshape(condition['function'](X), shape=(response.shape[0],1))\n",
      "#                    * tf.reshape(X[:, condition['variable']], shape=(response.shape[0],1)))\n",
      "#         boundary_value = temp_bc\n",
      "#         response *= (tf.constant(condition['value'], dtype='float64', shape=(response.shape[0],1))\n",
      "#                      - tf.reshape(X[:, condition['variable']], shape=(response.shape[0],1)))  \n",
      "#     response += boundary_value\n",
      "    return response\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method TrialSolution.call of <tensorflow.python.eager.function.TfMethodTarget object at 0x7f9403f710b8>> could not be transformed and will be staged without change. Error details can be found in the logs when running with the env variable AUTOGRAPH_VERBOSITY >= 1. Please report this to the AutoGraph team. Cause: Unexpected error transforming <bound method TrialSolution.call of <tensorflow.python.eager.function.TfMethodTarget object at 0x7f9403f710b8>>. If you believe this is due to a bug, please set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output when filing the bug report. Caused by: Failed to parse source code of <bound method TrialSolution.call of <tensorflow.python.eager.function.TfMethodTarget object at 0x7f9403f710b8>>, which Python reported as:\n",
      "  @tf.function\n",
      "  def call(self, X):\n",
      "    with tf.GradientTape() as tape:\n",
      "      X = tf.convert_to_tensor(X)\n",
      "      response = self.hidden_layer(X)\n",
      "      response = self.output_layer(response)\n",
      "      X1 = tf.concat([tf.reshape(X[:,0], shape=(X.shape[0], 1)),\n",
      "                      tf.constant(1.0, dtype='float64', shape=(X.shape[0], 1))], axis=1)\n",
      "#       print(X1)\n",
      "      tape.watch(X1)\n",
      "      response1 = self.hidden_layer(X1)\n",
      "#       print(response1)\n",
      "      response1 = self.output_layer(response1)\n",
      "    der_resp1 = tape.gradient(response1, X1)\n",
      "#     print(der_resp1)\n",
      "    der_resp1 = tf.reshape(der_resp1[:,1], shape=(response.shape[0],1))\n",
      "#     print(der_resp1)\n",
      "    x = tf.reshape(X[:,0], shape=(response.shape[0],1))\n",
      "    y = tf.reshape(X[:,1], shape=(response.shape[0],1))\n",
      "    one = tf.constant(1., dtype='float64', shape=(response.shape[0],1))\n",
      "    two = tf.constant(2., dtype='float64', shape=(response.shape[0],1))\n",
      "    pi = tf.constant(np.pi, dtype='float64', shape=(response.shape[0],1))\n",
      "    response -= response1\n",
      "    response -= der_resp1\n",
      "#     print(response)\n",
      "    response *= x*(one-x)*y\n",
      "    response += y * two * tf.sin(pi * x)\n",
      "\n",
      "#     print(response)\n",
      "#     boundary_value = tf.constant(0., dtype='float64', shape=(response.shape[0],1))\n",
      "\n",
      "#     for condition in self.conditions:\n",
      "#       vanishing = tf.constant(1., dtype='float64', shape=(response.shape[0],1))\n",
      "#       temp_bc = 0\n",
      "#       if condition['type'] == 'dirichlet':\n",
      "#         temp_bc = tf.reshape(condition['function'](X), shape=(response.shape[0],1))           \n",
      "#         for vanisher in self.conditions:\n",
      "#           if vanisher['variable'] != condition['variable'] and vanisher['value'] != condition['value']:\n",
      "#             if vanisher['type'] == 'dirichlet':\n",
      "#               vanishing *= (X[:, vanisher['variable']]\n",
      "#                                         - tf.constant(vanisher['value'], dtype='float64', shape=(response.shape[0],1)))\n",
      "#             elif vanisher['type'] == 'neumann':\n",
      "#               vanishing *= (X[:, vanisher['variable']]\n",
      "#                                         - tf.constant(vanisher['value'], dtype='float64', shape=(response.shape[0],1)))\n",
      "#         boundary_value += temp_bc * vanishing\n",
      "#         response *= (tf.constant(condition['value'], dtype='float64', shape=(response.shape[0],1))\n",
      "#                      - tf.reshape(X[:, condition['variable']], shape=(response.shape[0],1)))\n",
      "#       elif condition['type'] == 'neumann':\n",
      "#         temp_bc = (tf.reshape(condition['function'](X), shape=(response.shape[0],1))\n",
      "#                    * tf.reshape(X[:, condition['variable']], shape=(response.shape[0],1)))\n",
      "#         boundary_value = temp_bc\n",
      "#         response *= (tf.constant(condition['value'], dtype='float64', shape=(response.shape[0],1))\n",
      "#                      - tf.reshape(X[:, condition['variable']], shape=(response.shape[0],1)))  \n",
      "#     response += boundary_value\n",
      "    return response\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-2896445cc5af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mEPOCHS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m1000\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Epoch: {epoch+1} Loss: {train_loss.result().numpy()}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    424\u001b[0m     \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m     \u001b[0minitializer_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializer_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    427\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    368\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    369\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 370\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1311\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_input_signature\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1312\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1313\u001b[0;31m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1314\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1578\u001b[0m           or call_context_key not in self._function_cache.missed):\n\u001b[1;32m   1579\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1580\u001b[0;31m         \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1581\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1582\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   1510\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1511\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1512\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   1513\u001b[0m         self._function_attributes)\n\u001b[1;32m   1514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    692\u001b[0m                                           converted_func)\n\u001b[1;32m    693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 694\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, IndexedSlices,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    315\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    684\u001b[0m                   \u001b[0moptional_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mautograph_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m                   \u001b[0mforce_conversion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m               ), args, kwargs)\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m         \u001b[0;31m# Wrapping around a decorator allows checks like tf_inspect.getargspec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, owner, options, args, kwargs)\u001b[0m\n\u001b[1;32m    390\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m   \u001b[0;31m# The converted function's closure is simply inserted into the function's\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/tmpo6vj843e.py\u001b[0m in \u001b[0;36mtf__train_step\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtf__train_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiff_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConversionOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecursive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrip_decorators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_not_convert\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_conversion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptional_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minternal_convert_user_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0mgradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'gradient'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConversionOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecursive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrip_decorators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefun_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_not_convert\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_conversion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptional_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minternal_convert_user_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'apply_gradients'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConversionOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecursive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrip_decorators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefun_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_not_convert\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_conversion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptional_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minternal_convert_user_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, owner, options, args, kwargs)\u001b[0m\n\u001b[1;32m    390\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m   \u001b[0;31m# The converted function's closure is simply inserted into the function's\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/tmpqxehdjoq.py\u001b[0m in \u001b[0;36mtf__diff_loss\u001b[0;34m(network, inputs)\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0mtwo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'constant'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConversionOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecursive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrip_decorators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefun_12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_not_convert\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefun_13\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_not_convert\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_conversion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptional_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minternal_convert_user_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'dtype'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'float64'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0mpi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'constant'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConversionOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecursive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrip_decorators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefun_14\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_not_convert\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefun_15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_not_convert\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_conversion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptional_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minternal_convert_user_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'dtype'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'float64'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m   \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'square'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConversionOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecursive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrip_decorators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefun_16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_not_convert\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefun_17\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_not_convert\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_conversion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptional_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minternal_convert_user_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlaplace\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlaplace\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mresponse\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtwo\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mpi\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtwo\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m   \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "EPOCHS = 100000\n",
    "for epoch in range(EPOCHS):\n",
    "  train_step(samples)\n",
    "  if (epoch+1) % 1000 == 0:\n",
    "    print(f'Epoch: {epoch+1} Loss: {train_loss.result().numpy()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "new_shape = int(np.sqrt(samples.shape[0]))\n",
    "Ze5sol = tf.reshape(ts(samples), shape=(samples.shape[0],)).numpy()\n",
    "ax.plot_surface(X=samples[:,0].reshape((new_shape, new_shape)), Y=samples[:,1].reshape((new_shape, new_shape)), Z=Ze5sol.reshape((new_shape, new_shape)), label='Numerical - Training')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "Ze5anal = np.sin(np.pi*samples[:,0])*samples[:,1]**2\n",
    "Ze5diff = Ze5sol - Ze5anal\n",
    "ax.plot_surface(X=samples[:,0].reshape((new_shape, new_shape)), Y=samples[:,1].reshape((new_shape, new_shape)), Z=Ze5diff.reshape((new_shape, new_shape)), label='Analytic')\n",
    "# plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.abs(Ze5diff**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(np.abs(Ze5diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "Ze5anal = np.sin(np.pi*samples[:,0])*samples[:,1]**2\n",
    "Ze5diff = Ze5sol - Ze5anal\n",
    "ax.plot_surface(X=samples[:,0].reshape((new_shape, new_shape)), Y=samples[:,1].reshape((new_shape, new_shape)), Z=Ze5anal.reshape((new_shape, new_shape)), label='Analytic')\n",
    "# plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
