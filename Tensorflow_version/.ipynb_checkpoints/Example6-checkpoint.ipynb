{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raroog/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TrialSolution(tf.keras.models.Model):\n",
    "  def __init__(self, conditions, n_i, n_h, n_o=1, activation='sigmoid', equation_type='ODE'):\n",
    "    super(TrialSolution, self).__init__()\n",
    "    self.n_i = n_i\n",
    "    self.n_h = n_h\n",
    "    self.n_o = n_o\n",
    "    self.conditions = conditions\n",
    "    self.hidden_layer = tf.keras.layers.Dense(units=self.n_h, activation=activation)\n",
    "    self.output_layer = tf.keras.layers.Dense(units=self.n_o, activation='linear')\n",
    "    \n",
    "  def call(self, X):\n",
    "    with tf.GradientTape() as tape:\n",
    "      X = tf.convert_to_tensor(X)\n",
    "      response = self.hidden_layer(X)\n",
    "      response = self.output_layer(response)\n",
    "      X1 = tf.concat([tf.reshape(X[:,0], shape=(X.shape[0], 1)),\n",
    "                      tf.constant(1.0, dtype='float64', shape=(X.shape[0], 1))], axis=1)\n",
    "#       print(X1)\n",
    "      tape.watch(X1)\n",
    "      response1 = self.hidden_layer(X1)\n",
    "#       print(response1)\n",
    "      response1 = self.output_layer(response1)\n",
    "    der_resp1 = tape.gradient(response1, X1)\n",
    "    print(der_resp1)\n",
    "    der_resp1 = tf.reshape(der_resp1[:,1], shape=(response.shape[0],1))\n",
    "#     print(der_resp1)\n",
    "    x = tf.reshape(X[:,0], shape=(response.shape[0],1))\n",
    "    y = tf.reshape(X[:,1], shape=(response.shape[0],1))\n",
    "    one = tf.constant(1., dtype='float64', shape=(response.shape[0],1))\n",
    "    two = tf.constant(2., dtype='float64', shape=(response.shape[0],1))\n",
    "    pi = tf.constant(np.pi, dtype='float64', shape=(response.shape[0],1))\n",
    "#     response -= response1 + der_resp1\n",
    "#     print(response)\n",
    "    response *= x*(one-x)*y\n",
    "    response += y * two * tf.sin(pi * x)\n",
    "    \n",
    "#     print(response)\n",
    "#     boundary_value = tf.constant(0., dtype='float64', shape=(response.shape[0],1))\n",
    "    \n",
    "#     for condition in self.conditions:\n",
    "#       vanishing = tf.constant(1., dtype='float64', shape=(response.shape[0],1))\n",
    "#       temp_bc = 0\n",
    "#       if condition['type'] == 'dirichlet':\n",
    "#         temp_bc = tf.reshape(condition['function'](X), shape=(response.shape[0],1))           \n",
    "#         for vanisher in self.conditions:\n",
    "#           if vanisher['variable'] != condition['variable'] and vanisher['value'] != condition['value']:\n",
    "#             if vanisher['type'] == 'dirichlet':\n",
    "#               vanishing *= (X[:, vanisher['variable']]\n",
    "#                                         - tf.constant(vanisher['value'], dtype='float64', shape=(response.shape[0],1)))\n",
    "#             elif vanisher['type'] == 'neumann':\n",
    "#               vanishing *= (X[:, vanisher['variable']]\n",
    "#                                         - tf.constant(vanisher['value'], dtype='float64', shape=(response.shape[0],1)))\n",
    "#         boundary_value += temp_bc * vanishing\n",
    "#         response *= (tf.constant(condition['value'], dtype='float64', shape=(response.shape[0],1))\n",
    "#                      - tf.reshape(X[:, condition['variable']], shape=(response.shape[0],1)))\n",
    "#       elif condition['type'] == 'neumann':\n",
    "#         temp_bc = (tf.reshape(condition['function'](X), shape=(response.shape[0],1))\n",
    "#                    * tf.reshape(X[:, condition['variable']], shape=(response.shape[0],1)))\n",
    "#         boundary_value = temp_bc\n",
    "#         response *= (tf.constant(condition['value'], dtype='float64', shape=(response.shape[0],1))\n",
    "#                      - tf.reshape(X[:, condition['variable']], shape=(response.shape[0],1)))  \n",
    "#     response += boundary_value\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bcs = [{'variable':0, 'value':0, 'type':'dirichlet',\n",
    "        'function':lambda X: X[:,1]**3},\n",
    "        {'variable':0, 'value':0, 'type':'dirichlet',\n",
    "        'function':lambda X: (tf.constant(1., dtype='float64', shape=(X.shape[0],1))+ X[:,1]**3)*tf.exp(tf.constant(-1., dtype='float64', shape=(X.shape[0],1)))},\n",
    "        {'variable':1, 'value':0, 'type':'dirichlet',\n",
    "        'function':lambda X: X[:,0]*tf.exp(-X[:,0])},\n",
    "        {'variable':1, 'value':1, 'type':'dirichlet',\n",
    "        'function':lambda X: (X[:,0]+tf.constant(1., dtype='float64', shape=(X.shape[0],1)))*tf.exp(-X[:,0])}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_samples = 100\n",
    "X_p = np.linspace(0, 1, n_samples)\n",
    "Y_p = np.linspace(0, 1, n_samples)\n",
    "X_p, Y_p = np.meshgrid(X_p, Y_p)\n",
    "X_p = X_p.flatten()\n",
    "Y_p = Y_p.flatten()\n",
    "samples = np.array([X_p, Y_p]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ts = TrialSolution(conditions=bcs, n_i=2, n_h=10, n_o=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def diff_loss(network, inputs):\n",
    "  with tf.GradientTape() as tape2:\n",
    "    with tf.GradientTape() as tape:\n",
    "      inputs = tf.convert_to_tensor(inputs)\n",
    "      tape.watch(inputs)\n",
    "      tape2.watch(inputs)\n",
    "      response = network(inputs)  \n",
    "    grads = tape.gradient(response, inputs)\n",
    "  laplace = tape2.gradient(grads, inputs)\n",
    "#   print(grads)\n",
    "#   print(laplace)\n",
    "  two = tf.constant(2, dtype='float64')\n",
    "  pi = tf.constant(np.pi, dtype='float64')\n",
    "  loss = tf.square(laplace[:,0] + laplace[:,1]\n",
    "                   - tf.sin(pi*inputs[:,0])*(two  - pi**2*inputs[:,1]**2))\n",
    "  return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.1)\n",
    "train_loss = tf.keras.metrics.Mean('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(X):\n",
    "  with tf.GradientTape() as tape:\n",
    "    loss = diff_loss(ts, X)\n",
    "  gradients = tape.gradient(loss, ts.trainable_variables)\n",
    "  optimizer.apply_gradients(zip(gradients, ts.trainable_variables))\n",
    "  train_loss(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.10406493 0.1499706 ]\n",
      " [0.10396423 0.14985708]\n",
      " [0.10386284 0.14974278]\n",
      " ...\n",
      " [0.09146353 0.1358385 ]\n",
      " [0.09130799 0.13566561]\n",
      " [0.09115203 0.13549228]], shape=(10000, 2), dtype=float64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=135, shape=(10000, 1), dtype=float64, numpy=\n",
       "array([[0.00000000e+00],\n",
       "       [0.00000000e+00],\n",
       "       [0.00000000e+00],\n",
       "       ...,\n",
       "       [1.28239422e-01],\n",
       "       [6.41680613e-02],\n",
       "       [2.44929360e-16]])>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts(tf.convert_to_tensor(samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"trial_solution/MatMul_2:0\", shape=(10000, 2), dtype=float64)\n",
      "Tensor(\"trial_solution/MatMul_2:0\", shape=(10000, 2), dtype=float64)\n",
      "Epoch: 1000 Loss: 2.565467357635498\n",
      "Epoch: 2000 Loss: 1.3352611064910889\n",
      "Epoch: 3000 Loss: 0.9103174805641174\n",
      "Epoch: 4000 Loss: 0.6943308115005493\n",
      "Epoch: 5000 Loss: 0.5637388229370117\n",
      "Epoch: 6000 Loss: 0.4759729206562042\n",
      "Epoch: 7000 Loss: 0.4133424758911133\n",
      "Epoch: 8000 Loss: 0.36570489406585693\n",
      "Epoch: 9000 Loss: 0.3283294141292572\n",
      "Epoch: 10000 Loss: 0.29834502935409546\n",
      "Epoch: 11000 Loss: 0.27391543984413147\n",
      "Epoch: 12000 Loss: 0.25340670347213745\n",
      "Epoch: 13000 Loss: 0.2360510379076004\n",
      "Epoch: 14000 Loss: 0.22125670313835144\n",
      "Epoch: 15000 Loss: 0.2083158940076828\n",
      "Epoch: 16000 Loss: 0.1969624161720276\n",
      "Epoch: 17000 Loss: 0.1870223581790924\n",
      "Epoch: 18000 Loss: 0.17817144095897675\n",
      "Epoch: 19000 Loss: 0.170165553689003\n",
      "Epoch: 20000 Loss: 0.16303448379039764\n",
      "Epoch: 21000 Loss: 0.15658172965049744\n",
      "Epoch: 22000 Loss: 0.15063360333442688\n",
      "Epoch: 23000 Loss: 0.1452692300081253\n",
      "Epoch: 24000 Loss: 0.14033843576908112\n",
      "Epoch: 25000 Loss: 0.13579264283180237\n",
      "Epoch: 26000 Loss: 0.13159385323524475\n",
      "Epoch: 27000 Loss: 0.12769156694412231\n",
      "Epoch: 28000 Loss: 0.1240784227848053\n",
      "Epoch: 29000 Loss: 0.12073036283254623\n",
      "Epoch: 30000 Loss: 0.1175534650683403\n",
      "Epoch: 31000 Loss: 0.11462767422199249\n",
      "Epoch: 32000 Loss: 0.11187145113945007\n",
      "Epoch: 33000 Loss: 0.10927510261535645\n",
      "Epoch: 34000 Loss: 0.10684573650360107\n",
      "Epoch: 35000 Loss: 0.10456623136997223\n",
      "Epoch: 36000 Loss: 0.10237845778465271\n",
      "Epoch: 37000 Loss: 0.10033509135246277\n",
      "Epoch: 38000 Loss: 0.09835659712553024\n",
      "Epoch: 39000 Loss: 0.09651016443967819\n",
      "Epoch: 40000 Loss: 0.09474732726812363\n",
      "Epoch: 41000 Loss: 0.09307220578193665\n",
      "Epoch: 42000 Loss: 0.09147383272647858\n",
      "Epoch: 43000 Loss: 0.0899563878774643\n",
      "Epoch: 44000 Loss: 0.08850547671318054\n",
      "Epoch: 45000 Loss: 0.08711507171392441\n",
      "Epoch: 46000 Loss: 0.08578980714082718\n",
      "Epoch: 47000 Loss: 0.08449769020080566\n",
      "Epoch: 48000 Loss: 0.08328643441200256\n",
      "Epoch: 49000 Loss: 0.08211873471736908\n",
      "Epoch: 50000 Loss: 0.08099251240491867\n",
      "Epoch: 51000 Loss: 0.07991466671228409\n",
      "Epoch: 52000 Loss: 0.07887815684080124\n",
      "Epoch: 53000 Loss: 0.0778801366686821\n",
      "Epoch: 54000 Loss: 0.07690063118934631\n",
      "Epoch: 55000 Loss: 0.07597614824771881\n",
      "Epoch: 56000 Loss: 0.07507860660552979\n",
      "Epoch: 57000 Loss: 0.07420973479747772\n",
      "Epoch: 58000 Loss: 0.07336731255054474\n",
      "Epoch: 59000 Loss: 0.07256050407886505\n",
      "Epoch: 60000 Loss: 0.07178904116153717\n",
      "Epoch: 61000 Loss: 0.07103905081748962\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 100000\n",
    "for epoch in range(EPOCHS):\n",
    "  train_step(samples)\n",
    "  if (epoch+1) % 1000 == 0:\n",
    "    print(f'Epoch: {epoch+1} Loss: {train_loss.result().numpy()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "new_shape = int(np.sqrt(samples.shape[0]))\n",
    "Ze5sol = tf.reshape(ts(samples), shape=(samples.shape[0],)).numpy()\n",
    "ax.plot_surface(X=samples[:,0].reshape((new_shape, new_shape)), Y=samples[:,1].reshape((new_shape, new_shape)), Z=Ze5sol.reshape((new_shape, new_shape)), label='Numerical - Training')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "Ze5anal = np.sin(np.pi*samples[:,0])*samples[:,1]**2\n",
    "Ze5diff = Ze5sol - Ze5anal\n",
    "ax.plot_surface(X=samples[:,0].reshape((new_shape, new_shape)), Y=samples[:,1].reshape((new_shape, new_shape)), Z=Ze5diff.reshape((new_shape, new_shape)), label='Analytic')\n",
    "# plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.abs(Ze5diff).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(np.abs(Ze5diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "Ze5anal = np.sin(np.pi*samples[:,0])*samples[:,1]**2\n",
    "Ze5diff = Ze5sol - Ze5anal\n",
    "ax.plot_surface(X=samples[:,0].reshape((new_shape, new_shape)), Y=samples[:,1].reshape((new_shape, new_shape)), Z=Ze5anal.reshape((new_shape, new_shape)), label='Analytic')\n",
    "# plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
