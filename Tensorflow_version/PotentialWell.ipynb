{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raroog/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproduction: Shirvany, et. al., \"Numerical solution of the nonlinear Schrodinger equation by feedforward neural networks.\"\n",
    "\n",
    "We consider the Shroedinger equation in one dimension:\n",
    "$$\\frac{d^2}{dx^2}\\Psi(x)+V(x)\\Psi(x)=E\\Psi(x)$$\n",
    "For the Potential Well problem with $V(x)=0,\\, x\\in[0,L]$ and $V(x)=\\infty,\\, x\\notin(0,L)$ the boundary conditions become $\\Psi(0)=0$ and $\\Psi(L)=0$ with the domain $x\\in[0,L]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "L = 4.\n",
    "X_train = np.arange(0, L, 0.02) + 1e-8\n",
    "X_train = X_train.reshape(-1,1)\n",
    "X_test = np.arange(0, L, 0.001) + 1e-8\n",
    "X_test = X_test.reshape(-1,1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bcs = [{'variable':0, 'value':0, 'type':'dirichlet',\n",
    "        'function':lambda X: tf.constant(0., dtype='float64', shape=X.shape)},\n",
    "      {'variable':0, 'value':L, 'type':'dirichlet',\n",
    "        'function':lambda X: tf.constant(0., dtype='float64', shape=X.shape)},\n",
    "      {'variable':0, 'value':L, 'type':'dirichlet',\n",
    "        'function':lambda X: tf.constant(0., dtype='float64', shape=X.shape)}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The authors propose the solution of a form of a almost-shallow network where we have a single hidden layer with $n_h$ units with sigmoid activation function. Output of the hidden layer is passed to an output layer with $n_o=2$ linear units which in the end are reduced by multipication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Solution(tf.keras.models.Model):\n",
    "  def __init__(self, n_i, n_h, n_o=1, activation='sigmoid'):\n",
    "    super(Solution, self).__init__()\n",
    "    self.n_i = n_i\n",
    "    self.n_h = n_h\n",
    "    self.n_o = n_o\n",
    "    self.hidden_layer = tf.keras.layers.Dense(units=n_h, activation=activation)\n",
    "    self.output_layer = tf.keras.layers.Dense(units=n_o, activation='linear')\n",
    "    \n",
    "  def call(self, X):\n",
    "    X = tf.convert_to_tensor(X)\n",
    "    response = self.hidden_layer(X)\n",
    "    response = self.output_layer(X)\n",
    "    response = tf.math.reduce_prod(response, axis=1)\n",
    "    return response\n",
    "  \n",
    "  def train(self, X, conditions, eigen_value, loss_function, loss_boundary, epochs, verbose=True, message_frequency=1, learning_rate=0.1, optimizer_name='Adam'):\n",
    "    if not isinstance(epochs, int) or epochs < 1:\n",
    "      raise Exception('epochs parameter should be a positive integer.')\n",
    "    if not isinstance(message_frequency, int) or message_frequency < 1:\n",
    "      raise Exception(\n",
    "                'message_frequency parameter should be a positive integer.')\n",
    "    optimizer = 0\n",
    "    if optimizer_name == 'Adam':\n",
    "      optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    elif optimizer_name == 'SGD':\n",
    "      optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "    elif optimizer_name == 'Adagrad':\n",
    "      optimizer = tf.keras.optimizers.Adagrad(learning_rate=learning_rate)\n",
    "    train_loss = tf.keras.metrics.Mean('train')\n",
    "    @tf.function\n",
    "    def train_step(X, eigen_value):\n",
    "      with tf.GradientTape() as tape:\n",
    "        loss = loss_function(self, X, eigen_value)\n",
    "      gradients = tape.gradient(loss, self.trainable_variables)\n",
    "      optimizer.apply_gradients(\n",
    "                  zip(gradients, self.trainable_variables))\n",
    "      \n",
    "    @tf.function\n",
    "    def train_boundary(conditions):\n",
    "      with tf.GradientTape() as tape:\n",
    "        loss = loss_boundary(self, conditions)\n",
    "      gradients = tape.gradient(loss, self.trainable_variables)\n",
    "      optimizer.apply_gradients(\n",
    "                  zip(gradients, self.trainable_variables))\n",
    "      \n",
    "    for epoch in range(epochs):\n",
    "      for x in X:\n",
    "        x_tensor = tf.reshape(x, shape=(1, X.shape[1]))\n",
    "        train_step(x_tensor, eigen_value)\n",
    "      train_boundary(conditions)\n",
    "      train_loss(loss_function(self, X, eigen_value) + loss_boundary(self, conditions))\n",
    "      if (epoch+1) % message_frequency == 0:\n",
    "        print(f'Epoch: {epoch+1} Loss: {train_loss.result().numpy()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accroding to the paper:\n",
    "\n",
    ">The ANN is trained via the gradient-descent back-propagation method with momentum\n",
    "term for minimizing the non-negative energy function that is formulated from Schrodinger equation Eq. (6)\n",
    "and the available boundary conditions.\n",
    "\n",
    "and\n",
    "\n",
    ">In the train\n",
    "state of the network the adjustable parameters of the networks (weights and biases) are tuned by a proper\n",
    "learning algorithm to minimize the energy function of the network. We train the network via the fast converge\n",
    "gradient-descend back-propagation method with momentum term [7,23,24] for the non-negative energy func-\n",
    "tion.\n",
    "\n",
    "We concluded that it can realised by using the Adam optimizer with online learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loss is defined by sum of unsupervised minimalization of the equation and by supervised optimization for MSE for the boundary conditions:\n",
    "$$Loss(N)=\\sum_i \\left(\\Delta\\Psi(N(x_i))+E\\Psi(N(x_i))\\right)^2 + \\sum_k (\\Psi(N(x_k))-C_k)^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loss(network, X, eigen_value):\n",
    "  X = tf.convert_to_tensor(X)\n",
    "  with tf.GradientTape() as tape1:\n",
    "    with tf.GradientTape() as tape2:\n",
    "      tape1.watch(X)\n",
    "      tape2.watch(X)\n",
    "      response = network(X)\n",
    "    grads = tape2.gradient(response, X)\n",
    "  laplace = tape1.gradient(grads, X)\n",
    "#   half = tf.constant(0.5, shape=(X.shape[0], 1), dtype='float64')\n",
    "  eigen_value_tensor = tf.constant(eigen_value, shape=(X.shape[0], 1), dtype='float64')\n",
    "  loss = tf.square(laplace + eigen_value_tensor * response)\n",
    "  return loss      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loss_boundary(network, conditions):\n",
    "  loss = 0\n",
    "  for condition in conditions:\n",
    "    temp_X = tf.convert_to_tensor(np.array([condition['value']]).reshape((1,1)))\n",
    "    loss += tf.square(network(temp_X) - condition['function'](temp_X))\n",
    "  return loss      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimal size of the network found by the autors is $n_h=105$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sol = Solution(n_i=1, n_h=40, n_o=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check if such a solution finds the eigen function corresponidng to the eigen_value $E=0.61$ for $n=1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0425 16:06:29.106647 140163640977152 deprecation.py:323] From /home/raroog/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:167: setdiff1d (from tensorflow.python.ops.array_ops) is deprecated and will be removed after 2018-11-30.\n",
      "Instructions for updating:\n",
      "This op will be removed after the deprecation date. Please switch to tf.sets.difference().\n",
      "W0425 16:06:29.421125 140163640977152 optimizer_v2.py:928] Gradients does not exist for variables ['solution/dense/kernel:0', 'solution/dense/bias:0'] when minimizing the loss.\n",
      "W0425 16:06:30.632727 140163640977152 optimizer_v2.py:928] Gradients does not exist for variables ['solution/dense/kernel:0', 'solution/dense/bias:0'] when minimizing the loss.\n",
      "W0425 16:06:31.555563 140163640977152 optimizer_v2.py:928] Gradients does not exist for variables ['solution/dense/kernel:0', 'solution/dense/bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Loss: 0.08791682869195938\n",
      "Epoch: 2 Loss: 0.12983863055706024\n",
      "Epoch: 3 Loss: 0.16996386647224426\n",
      "Epoch: 4 Loss: 0.19705641269683838\n",
      "Epoch: 5 Loss: 0.209036722779274\n",
      "Epoch: 6 Loss: 0.20900586247444153\n",
      "Epoch: 7 Loss: 0.2016897350549698\n",
      "Epoch: 8 Loss: 0.1909661442041397\n",
      "Epoch: 9 Loss: 0.1791713386774063\n",
      "Epoch: 10 Loss: 0.16746602952480316\n",
      "Epoch: 11 Loss: 0.15635187923908234\n",
      "Epoch: 12 Loss: 0.1460133194923401\n",
      "Epoch: 13 Loss: 0.13649828732013702\n",
      "Epoch: 14 Loss: 0.1278017908334732\n",
      "Epoch: 15 Loss: 0.11988908797502518\n",
      "Epoch: 16 Loss: 0.11272172629833221\n",
      "Epoch: 17 Loss: 0.1062367781996727\n",
      "Epoch: 18 Loss: 0.10040773451328278\n",
      "Epoch: 19 Loss: 0.09515030682086945\n",
      "Epoch: 20 Loss: 0.09040126949548721\n",
      "Epoch: 21 Loss: 0.08609898388385773\n",
      "Epoch: 22 Loss: 0.08218616247177124\n",
      "Epoch: 23 Loss: 0.07861308008432388\n",
      "Epoch: 24 Loss: 0.07533760368824005\n",
      "Epoch: 25 Loss: 0.07232412695884705\n",
      "Epoch: 26 Loss: 0.06954243779182434\n",
      "Epoch: 27 Loss: 0.06696678698062897\n",
      "Epoch: 28 Loss: 0.06457512080669403\n",
      "Epoch: 29 Loss: 0.062348391860723495\n",
      "Epoch: 30 Loss: 0.06027011200785637\n",
      "Epoch: 31 Loss: 0.058325912803411484\n",
      "Epoch: 32 Loss: 0.05650322884321213\n",
      "Epoch: 33 Loss: 0.05479101091623306\n",
      "Epoch: 34 Loss: 0.053179509937763214\n",
      "Epoch: 35 Loss: 0.051660094410181046\n",
      "Epoch: 36 Loss: 0.050225093960762024\n",
      "Epoch: 37 Loss: 0.04886765778064728\n",
      "Epoch: 38 Loss: 0.047581665217876434\n",
      "Epoch: 39 Loss: 0.04636162519454956\n",
      "Epoch: 40 Loss: 0.0452025830745697\n",
      "Epoch: 41 Loss: 0.0441000796854496\n",
      "Epoch: 42 Loss: 0.04305008053779602\n",
      "Epoch: 43 Loss: 0.04204891622066498\n",
      "Epoch: 44 Loss: 0.04109325632452965\n",
      "Epoch: 45 Loss: 0.04018007218837738\n",
      "Epoch: 46 Loss: 0.03930659219622612\n",
      "Epoch: 47 Loss: 0.03847028315067291\n",
      "Epoch: 48 Loss: 0.03766882047057152\n",
      "Epoch: 49 Loss: 0.03690006956458092\n",
      "Epoch: 50 Loss: 0.03616206720471382\n",
      "Epoch: 51 Loss: 0.035453006625175476\n",
      "Epoch: 52 Loss: 0.03477121889591217\n",
      "Epoch: 53 Loss: 0.03411515802145004\n",
      "Epoch: 54 Loss: 0.033483393490314484\n",
      "Epoch: 55 Loss: 0.03287460654973984\n",
      "Epoch: 56 Loss: 0.032287560403347015\n",
      "Epoch: 57 Loss: 0.03172111138701439\n",
      "Epoch: 58 Loss: 0.031174195930361748\n",
      "Epoch: 59 Loss: 0.030645819380879402\n",
      "Epoch: 60 Loss: 0.030135056003928185\n",
      "Epoch: 61 Loss: 0.029641086235642433\n",
      "Epoch: 62 Loss: 0.029164869338274002\n",
      "Epoch: 63 Loss: 0.028827985748648643\n",
      "Epoch: 64 Loss: 0.029142599552869797\n",
      "Epoch: 65 Loss: 0.028808224946260452\n",
      "Epoch: 66 Loss: 0.028372747823596\n",
      "Epoch: 67 Loss: 0.02794940583407879\n",
      "Epoch: 68 Loss: 0.027538402006030083\n",
      "Epoch: 69 Loss: 0.027139296755194664\n",
      "Epoch: 70 Loss: 0.026751592755317688\n",
      "Epoch: 71 Loss: 0.026374809443950653\n",
      "Epoch: 72 Loss: 0.026008494198322296\n",
      "Epoch: 73 Loss: 0.025652213022112846\n",
      "Epoch: 74 Loss: 0.02530556172132492\n",
      "Epoch: 75 Loss: 0.02496815286576748\n",
      "Epoch: 76 Loss: 0.02463962510228157\n",
      "Epoch: 77 Loss: 0.02431963011622429\n",
      "Epoch: 78 Loss: 0.02400784008204937\n",
      "Epoch: 79 Loss: 0.02370394393801689\n",
      "Epoch: 80 Loss: 0.023407643660902977\n",
      "Epoch: 81 Loss: 0.02311865985393524\n",
      "Epoch: 82 Loss: 0.022836726158857346\n",
      "Epoch: 83 Loss: 0.022561585530638695\n",
      "Epoch: 84 Loss: 0.02229299396276474\n",
      "Epoch: 85 Loss: 0.022030724212527275\n",
      "Epoch: 86 Loss: 0.021774552762508392\n",
      "Epoch: 87 Loss: 0.021524270996451378\n",
      "Epoch: 88 Loss: 0.021279675886034966\n",
      "Epoch: 89 Loss: 0.021040579304099083\n",
      "Epoch: 90 Loss: 0.020806794986128807\n",
      "Epoch: 91 Loss: 0.02057814784348011\n",
      "Epoch: 92 Loss: 0.02035447396337986\n",
      "Epoch: 93 Loss: 0.020135607570409775\n",
      "Epoch: 94 Loss: 0.019921399652957916\n",
      "Epoch: 95 Loss: 0.019711699336767197\n",
      "Epoch: 96 Loss: 0.019506370648741722\n",
      "Epoch: 97 Loss: 0.0193052738904953\n",
      "Epoch: 98 Loss: 0.019108280539512634\n",
      "Epoch: 99 Loss: 0.018915267661213875\n",
      "Epoch: 100 Loss: 0.01872611604630947\n"
     ]
    }
   ],
   "source": [
    "sol.train(X=X_train, conditions=bcs, eigen_value=0.61, loss_function=loss, loss_boundary=loss_boundary, epochs=100, message_frequency=1, learning_rate=0.01, optimizer_name='Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7a0d9502e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_train = sol.call(tf.convert_to_tensor(X_train, dtype='float64')).numpy()\n",
    "pred_test = sol(tf.convert_to_tensor(X_test, dtype='float64')).numpy()\n",
    "plt.scatter(X_train, pred_train, c='r', label='Numerical - Training', marker='+', s=30)\n",
    "plt.plot(X_test, pred_test, c='g', label='Numerical - Test')\n",
    "plt.plot(X_test, np.sin(np.pi/L*X_test), c='b', label='Analytic')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Without much supprise, the network converges to the trivial vanishing solution of the equation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
