{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ShallowNetwork"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test for RMSE\n",
    "\n",
    "Let's test if the written shallow network class works for a simple case of fitting it to the cosine function with the RMSE loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.arange(0, 2 * np.pi, 0.03)\n",
    "X = X.reshape((X.shape[0], 1, 1))\n",
    "Y = np.sin(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definining loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loss_function_single_point(self, point, ground_truth):\n",
    "        N = self.forward_pass(point, 0)\n",
    "        loss = np.sqrt(((N - ground_truth) ** 2).sum())\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loss_function_all(self, samples, labels):\n",
    "        loss = 0\n",
    "        n_inv = len(samples) ** -1\n",
    "        for i in range(samples.shape[0]):\n",
    "            loss += self.loss_function_single_point(self, samples[i], labels[i]) ** 2\n",
    "        loss *= n_inv\n",
    "        loss = np.sqrt(loss)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the update rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bias_change_point(self, point, label):\n",
    "  db = np.zeros((self.hidden_dim, 1)).astype(dtype=\"float64\")\n",
    "  change = self.forward_pass(point, 0) - label\n",
    "  loss = self.loss_function_single_point(self, point, label)\n",
    "  db_N = self.network_derivative_bias(point, 0)\n",
    "  for m in range(self.hidden_dim):\n",
    "    for j in range(self.visible_dim):\n",
    "      db[m] += change[j] * db_N[j, 0, m]\n",
    "  db /= loss\n",
    "  return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hidden_weights_change_point(self, point, label):\n",
    "  dH = np.zeros((self.hidden_dim, self.input_dim)).astype(dtype=\"float64\")\n",
    "  change = self.forward_pass(point, 0) - label\n",
    "  loss = self.loss_function_single_point(self, point, label)\n",
    "  dH_N = self.network_derivative_hidden_weights(point, 0)\n",
    "  for m in range(self.hidden_dim):\n",
    "    for p in range(self.input_dim):\n",
    "      for j in range(self.visible_dim):\n",
    "        dH[m, p] += change[j] * dH_N[j, 0, m, p]\n",
    "  dH /= loss\n",
    "  return dH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def visible_weights_change_point(self, point, label):\n",
    "  dV = np.zeros((self.visible_dim, self.hidden_dim)).astype(dtype=\"float64\")\n",
    "  change = self.forward_pass(point, 0) - label\n",
    "  loss = self.loss_function_single_point(self, point, label)\n",
    "  dV_N = self.network_derivative_visible_weights(point, 0)\n",
    "  for m in range(self.visible_dim):\n",
    "    for p in range(self.hidden_dim):\n",
    "      for j in range(self.visible_dim):\n",
    "        dV[m, p] += change[j] * dV_N[j, 0, m, p]\n",
    "  dV /= loss\n",
    "  return dV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the netowork for the task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "network = ShallowNetwork.ShallowNetwork(loss_function=loss_function_all,\n",
    "                                        loss_function_single_point=loss_function_single_point,\n",
    "                                       bias_change=bias_change_point,\n",
    "                                       hidden_weights_change=hidden_weights_change_point,\n",
    "                                       visible_weights_change=visible_weights_change_point,\n",
    "                                       hidden_dim=50, unsupervised=False, momentum=0, learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Loss function: 1.455663928971233\n",
      "Epoch: 2 Loss function: 0.5188670065789509\n",
      "Epoch: 3 Loss function: 0.48341567094040266\n",
      "Epoch: 4 Loss function: 0.3369823755050468\n",
      "Epoch: 5 Loss function: 0.4616042618537419\n",
      "Epoch: 6 Loss function: 0.7983873995643652\n",
      "Epoch: 7 Loss function: 0.271004329583058\n",
      "Epoch: 8 Loss function: 0.28322646475978314\n",
      "Epoch: 9 Loss function: 0.38866982289359964\n",
      "Epoch: 10 Loss function: 0.36118477245241903\n"
     ]
    }
   ],
   "source": [
    "network.train(samples=X, labels=Y, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAD8CAYAAACfF6SlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ffaf45ab0b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Y2 = np.array([network.forward_pass(X[i], 0) for i in range(X.shape[0])])\n",
    "Xp = X.reshape((X.shape[0],))\n",
    "Yp = Y.reshape((Y.shape[0],))\n",
    "plt.plot(Xp, Yp, label='Ground truth')\n",
    "plt.scatter(Xp, Y2, label='Predictions')\n",
    "plt.legend()\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trial Solution class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trial_Solution:\n",
    "  def __init__(self, loss_function, loss_function_single_point,\n",
    "               bias_change, hidden_weights_change, visible_weights_change,\n",
    "               boundary_condition_value_function, boundary_vanishing_function,\n",
    "               input_dim=1, hidden_dim=1, output_dim=1, momentum=0, learning_rate=0.1):\n",
    "    # Dimensions of the Shallow Network\n",
    "    self.input_dim = input_dim\n",
    "    self.hidden_dim = hidden_dim\n",
    "    self.output_dim = output_dim\n",
    "    \n",
    "    # Defining all of the three parts of the trial solution f(X)=A(X)+B(X)N(X)\n",
    "    # A(X) is a function fullfiling the boundary or initial conditions\n",
    "    self.boundary_condition_value_function = boundary_condition_value_function\n",
    "    # B(X) is a function vanishing on the boundary or in the initial moment\n",
    "    self.boundary_vanishing_function = boundary_vanishing_function\n",
    "    # N(X) is the Shallow Network\n",
    "    self.network = ShallowNetwork.ShallowNetwork(\n",
    "      input_dim=self.input_dim, hidden_dim=self.hidden_dim, visible_dim=self.output_dim,\n",
    "      momentum=momentum, learning_rate=learning_rate, loss_function=loss_function,\n",
    "      loss_function_single_point=loss_function_single_point, bias_change=bias_change,\n",
    "      hidden_weights_change=hidden_weights_change, visible_weights_change=visible_weights_change,\n",
    "      unsupervised=True)\n",
    "\n",
    "  def predict(self, X):\n",
    "    return self.boundary_condition_value_function(X) + self.boundary_vanishing_function(X) * self.network.forward_pass(X, 0)\n",
    "    \n",
    "  def train(self, samples, epochs):\n",
    "    self.network.train(samples=samples, epochs=epochs, labels=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1\n",
    "\n",
    "$\\frac{d}{dx}\\Psi+(x+\\frac{1+3x^2}{1+x+x^3})\\Psi=x^3+2x+x^2\\frac{1+3x^2}{1+x+x^3}$\n",
    "\n",
    "With boundary initial condition $\\Psi(0)=1$ and domain $x\\in[0,1]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xe1 = np.arange(0,1,0.1).reshape((10,1,1)) + 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def example1_initial_value(point):\n",
    "  return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def example1_boundary_vanishing(point):\n",
    "  return point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def example1_loss_function_single_point(self, point, non_squared=False, *kwargs):\n",
    "  N = self.forward_pass(point, 0)\n",
    "  dN = self.forward_pass(point, 1)\n",
    "  loss = (\n",
    "      point * dN + N + (point + (1 + 3 * point ** 2)/(1 + point + point ** 3)) * (1 + point * N) \n",
    "      - point ** 3 - 2 * point - (1 + 3 * point ** 2)/(1 + point + point ** 3)\n",
    "    )\n",
    "  if not non_squared:\n",
    "    loss = loss ** 2\n",
    "  return loss[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def example1_loss_function(self, samples, *kwargs):\n",
    "  loss = 0\n",
    "  for i in range(samples.shape[0]):\n",
    "    loss += self.loss_function_single_point(self, samples[i])\n",
    "  return loss/samples.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def example1_bias_change(self, point, label, *kwargs):\n",
    "  db = np.zeros((self.hidden_dim, 1)).astype(dtype=\"float64\")\n",
    "  loss_sqrt = self.loss_function_single_point(self, point, non_squared=True)\n",
    "  db_N = self.network_derivative_bias(point, 0)\n",
    "  db_DN = self.network_derivative_bias(point, 1)\n",
    "  point = point.reshape((1,))\n",
    "  for m in range(self.hidden_dim):\n",
    "    db[m] += 2 * loss_sqrt * (\n",
    "      point * db_DN[0, 0, m] + db_N[0, 0, m] + (point + (1 + 3 * point ** 2)/(1 + point + point ** 3)) * point * db_N[0, 0, m])\n",
    "  return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def example1_hidden_weights_change(self, point, *kwargs):\n",
    "  dH = np.zeros((self.hidden_dim, self.input_dim)).astype(dtype=\"float64\")\n",
    "  loss_sqrt = self.loss_function_single_point(self, point, non_squared=True)\n",
    "  dH_N = self.network_derivative_hidden_weights(point, 0)\n",
    "  dH_DN = self.network_derivative_hidden_weights(point, 1)\n",
    "  for m in range(self.hidden_dim):\n",
    "    for p in range(self.input_dim):\n",
    "      dH[m, p] += 2 * loss_sqrt * (\n",
    "        point * dH_DN[0, 0, m, p] + dH_N[0, 0, m, p] + (point + (1 + 3 * point ** 2)/(1 + point + point ** 3)) * point * dH_N[0, 0, m, p])\n",
    "  return dH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def example1_visible_weights_change(self, point, *kwargs):\n",
    "  dV = np.zeros((self.visible_dim, self.hidden_dim)).astype(dtype=\"float64\")\n",
    "  loss_sqrt = self.loss_function_single_point(self, point, non_squared=True)\n",
    "  dV_N = self.network_derivative_visible_weights(point, 0)\n",
    "  dV_DN = self.network_derivative_visible_weights(point, 1)\n",
    "  for m in range(self.visible_dim):\n",
    "    for p in range(self.hidden_dim):\n",
    "      dV[m, p] += 2 * loss_sqrt * (\n",
    "        point * dV_DN[0, 0, m, p] + dV_N[0, 0, m, p] + (point + (1 + 3 * point ** 2)/(1 + point + point ** 3)) * point * dV_N[0, 0, m, p])\n",
    "  return dV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example1_trial_solution = Trial_Solution(loss_function=example1_loss_function,\n",
    "                                        loss_function_single_point=example1_loss_function_single_point,\n",
    "                                        bias_change=example1_bias_change,\n",
    "                                        hidden_weights_change=example1_hidden_weights_change,\n",
    "                                        visible_weights_change=example1_visible_weights_change,\n",
    "                                        boundary_condition_value_function=example1_initial_value,\n",
    "                                        boundary_vanishing_function=example1_boundary_vanishing,\n",
    "                                        input_dim=1, hidden_dim=10, output_dim=1, learning_rate=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Loss function: 0.07315006775382604\n",
      "Epoch: 2 Loss function: 0.06969376998696535\n",
      "Epoch: 3 Loss function: 0.06646657910271303\n",
      "Epoch: 4 Loss function: 0.06345393979347101\n",
      "Epoch: 5 Loss function: 0.06063868789608538\n",
      "Epoch: 6 Loss function: 0.05800255027031549\n",
      "Epoch: 7 Loss function: 0.05553544796607011\n",
      "Epoch: 8 Loss function: 0.05322187587054057\n",
      "Epoch: 9 Loss function: 0.05105420518526169\n",
      "Epoch: 10 Loss function: 0.04901940954181729\n",
      "Epoch: 11 Loss function: 0.04710536819247578\n",
      "Epoch: 12 Loss function: 0.04530431288862667\n",
      "Epoch: 13 Loss function: 0.04360921893277202\n",
      "Epoch: 14 Loss function: 0.042013164262687565\n",
      "Epoch: 15 Loss function: 0.04050840174585313\n",
      "Epoch: 16 Loss function: 0.0390889683039259\n",
      "Epoch: 17 Loss function: 0.03774775037957541\n",
      "Epoch: 18 Loss function: 0.036482442031458714\n",
      "Epoch: 19 Loss function: 0.0352844766160883\n",
      "Epoch: 20 Loss function: 0.03415096332617892\n",
      "Epoch: 21 Loss function: 0.0330771500484824\n",
      "Epoch: 22 Loss function: 0.032060141906648035\n",
      "Epoch: 23 Loss function: 0.031096642203621194\n",
      "Epoch: 24 Loss function: 0.03018186773474924\n",
      "Epoch: 25 Loss function: 0.029313388234650094\n",
      "Epoch: 26 Loss function: 0.028488719906758758\n",
      "Epoch: 27 Loss function: 0.02770551108302911\n",
      "Epoch: 28 Loss function: 0.02696029388192881\n",
      "Epoch: 29 Loss function: 0.02625030224770055\n",
      "Epoch: 30 Loss function: 0.025574088937596058\n",
      "Epoch: 31 Loss function: 0.02492994914551646\n",
      "Epoch: 32 Loss function: 0.024316134524581888\n",
      "Epoch: 33 Loss function: 0.023730506117818097\n",
      "Epoch: 34 Loss function: 0.023171547141974124\n",
      "Epoch: 35 Loss function: 0.022637080983716536\n",
      "Epoch: 36 Loss function: 0.022126480525631816\n",
      "Epoch: 37 Loss function: 0.021638315302117038\n",
      "Epoch: 38 Loss function: 0.021171561523599572\n",
      "Epoch: 39 Loss function: 0.02072474565851273\n",
      "Epoch: 40 Loss function: 0.020296497185824575\n",
      "Epoch: 41 Loss function: 0.01988637372740954\n",
      "Epoch: 42 Loss function: 0.019493250795966026\n",
      "Epoch: 43 Loss function: 0.019116498882625708\n",
      "Epoch: 44 Loss function: 0.018754996145436242\n",
      "Epoch: 45 Loss function: 0.01840774193915052\n",
      "Epoch: 46 Loss function: 0.018074661249837053\n",
      "Epoch: 47 Loss function: 0.01775420290717438\n",
      "Epoch: 48 Loss function: 0.017446343832774908\n",
      "Epoch: 49 Loss function: 0.01715022019651002\n",
      "Epoch: 50 Loss function: 0.016865391033799963\n",
      "Epoch: 51 Loss function: 0.01659101755283943\n",
      "Epoch: 52 Loss function: 0.016326988673654667\n",
      "Epoch: 53 Loss function: 0.016072564850036605\n",
      "Epoch: 54 Loss function: 0.015827809970588032\n",
      "Epoch: 55 Loss function: 0.015591708649707405\n",
      "Epoch: 56 Loss function: 0.015363742299482102\n",
      "Epoch: 57 Loss function: 0.015143723212419441\n",
      "Epoch: 58 Loss function: 0.014931592221118192\n",
      "Epoch: 59 Loss function: 0.014726532123103644\n",
      "Epoch: 60 Loss function: 0.014528865611617125\n",
      "Epoch: 61 Loss function: 0.01433759002498979\n",
      "Epoch: 62 Loss function: 0.014152936770444099\n",
      "Epoch: 63 Loss function: 0.013974224577047006\n",
      "Epoch: 64 Loss function: 0.013801454600885115\n",
      "Epoch: 65 Loss function: 0.013634214270167968\n",
      "Epoch: 66 Loss function: 0.013472186389985288\n",
      "Epoch: 67 Loss function: 0.01331526030697614\n",
      "Epoch: 68 Loss function: 0.013163345558542639\n",
      "Epoch: 69 Loss function: 0.013016101870848043\n",
      "Epoch: 70 Loss function: 0.012873365434261949\n",
      "Epoch: 71 Loss function: 0.012735035525847326\n",
      "Epoch: 72 Loss function: 0.012600904860028983\n",
      "Epoch: 73 Loss function: 0.012470832369331875\n",
      "Epoch: 74 Loss function: 0.012344592407833116\n",
      "Epoch: 75 Loss function: 0.012221909892664296\n",
      "Epoch: 76 Loss function: 0.012102815426646278\n",
      "Epoch: 77 Loss function: 0.011987107560865568\n",
      "Epoch: 78 Loss function: 0.011874630115979544\n",
      "Epoch: 79 Loss function: 0.011765394013393746\n",
      "Epoch: 80 Loss function: 0.011659103000790292\n",
      "Epoch: 81 Loss function: 0.011555709185165023\n",
      "Epoch: 82 Loss function: 0.011455067431634137\n",
      "Epoch: 83 Loss function: 0.01135727981315259\n",
      "Epoch: 84 Loss function: 0.011262049351382829\n",
      "Epoch: 85 Loss function: 0.01116929583686065\n",
      "Epoch: 86 Loss function: 0.01107899251790942\n",
      "Epoch: 87 Loss function: 0.01099094450786204\n",
      "Epoch: 88 Loss function: 0.01090523832950463\n",
      "Epoch: 89 Loss function: 0.010821662083324034\n",
      "Epoch: 90 Loss function: 0.010740235457945795\n",
      "Epoch: 91 Loss function: 0.010660821218210482\n",
      "Epoch: 92 Loss function: 0.010583354987193726\n",
      "Epoch: 93 Loss function: 0.010507769589029072\n",
      "Epoch: 94 Loss function: 0.010433955501289106\n",
      "Epoch: 95 Loss function: 0.010361917849530545\n",
      "Epoch: 96 Loss function: 0.010291614565438301\n",
      "Epoch: 97 Loss function: 0.010222909394932568\n",
      "Epoch: 98 Loss function: 0.010155860596583622\n",
      "Epoch: 99 Loss function: 0.010090334966542944\n",
      "Epoch: 100 Loss function: 0.010026285457524707\n",
      "Epoch: 101 Loss function: 0.009963647747390614\n",
      "Epoch: 102 Loss function: 0.009902440289866624\n",
      "Epoch: 103 Loss function: 0.00984257883044318\n",
      "Epoch: 104 Loss function: 0.009783957005140547\n",
      "Epoch: 105 Loss function: 0.009726624024915078\n",
      "Epoch: 106 Loss function: 0.009670516144324872\n",
      "Epoch: 107 Loss function: 0.009615586314132289\n",
      "Epoch: 108 Loss function: 0.009561811800069339\n",
      "Epoch: 109 Loss function: 0.009509155121201563\n",
      "Epoch: 110 Loss function: 0.009457564682435686\n",
      "Epoch: 111 Loss function: 0.00940704898261778\n",
      "Epoch: 112 Loss function: 0.009357542045176996\n",
      "Epoch: 113 Loss function: 0.009309050354539224\n",
      "Epoch: 114 Loss function: 0.009261478815262979\n",
      "Epoch: 115 Loss function: 0.009214885525605\n",
      "Epoch: 116 Loss function: 0.009169148360309671\n",
      "Epoch: 117 Loss function: 0.009124307335056963\n",
      "Epoch: 118 Loss function: 0.009080295423129063\n",
      "Epoch: 119 Loss function: 0.009037155649636693\n",
      "Epoch: 120 Loss function: 0.008994770815319214\n",
      "Epoch: 121 Loss function: 0.008953168913366337\n",
      "Epoch: 122 Loss function: 0.008912331072743666\n",
      "Epoch: 123 Loss function: 0.008872227425136967\n",
      "Epoch: 124 Loss function: 0.008832848958333684\n",
      "Epoch: 125 Loss function: 0.008794171863562213\n",
      "Epoch: 126 Loss function: 0.008756170651853405\n",
      "Epoch: 127 Loss function: 0.00871883594621747\n",
      "Epoch: 128 Loss function: 0.00868214514939653\n",
      "Epoch: 129 Loss function: 0.008646052817818826\n",
      "Epoch: 130 Loss function: 0.008610576560270915\n",
      "Epoch: 131 Loss function: 0.008575691320912996\n",
      "Epoch: 132 Loss function: 0.008541381528039535\n",
      "Epoch: 133 Loss function: 0.00850763410002965\n",
      "Epoch: 134 Loss function: 0.008474441257814857\n",
      "Epoch: 135 Loss function: 0.008441776673610946\n",
      "Epoch: 136 Loss function: 0.008409649734303451\n",
      "Epoch: 137 Loss function: 0.008378021496717191\n",
      "Epoch: 138 Loss function: 0.008346871207616532\n",
      "Epoch: 139 Loss function: 0.008316209093862648\n",
      "Epoch: 140 Loss function: 0.008286002466265267\n",
      "Epoch: 141 Loss function: 0.008256248682420034\n",
      "Epoch: 142 Loss function: 0.008226964466988406\n",
      "Epoch: 143 Loss function: 0.008198098384055335\n",
      "Epoch: 144 Loss function: 0.008169663067723426\n",
      "Epoch: 145 Loss function: 0.008141638547986541\n",
      "Epoch: 146 Loss function: 0.008114019085625968\n",
      "Epoch: 147 Loss function: 0.008086787673236428\n",
      "Epoch: 148 Loss function: 0.008059940658830556\n",
      "Epoch: 149 Loss function: 0.008033469748415062\n",
      "Epoch: 150 Loss function: 0.008007355845001625\n",
      "Epoch: 151 Loss function: 0.007981587907025998\n",
      "Epoch: 152 Loss function: 0.007956192956386483\n",
      "Epoch: 153 Loss function: 0.007931120583703273\n",
      "Epoch: 154 Loss function: 0.007906392544404593\n",
      "Epoch: 155 Loss function: 0.00788199335740613\n",
      "Epoch: 156 Loss function: 0.007857927579817873\n",
      "Epoch: 157 Loss function: 0.007834163674067031\n",
      "Epoch: 158 Loss function: 0.007810699043612151\n",
      "Epoch: 159 Loss function: 0.007787546519089877\n",
      "Epoch: 160 Loss function: 0.0077646697416615075\n",
      "Epoch: 161 Loss function: 0.00774208745750161\n",
      "Epoch: 162 Loss function: 0.0077197910659132256\n",
      "Epoch: 163 Loss function: 0.007697759093456702\n",
      "Epoch: 164 Loss function: 0.007675988810434529\n",
      "Epoch: 165 Loss function: 0.007654474056692316\n",
      "Epoch: 166 Loss function: 0.007633226092228519\n",
      "Epoch: 167 Loss function: 0.00761222142845001\n",
      "Epoch: 168 Loss function: 0.007591474002128573\n",
      "Epoch: 169 Loss function: 0.007570968016942023\n",
      "Epoch: 170 Loss function: 0.007550690092879825\n",
      "Epoch: 171 Loss function: 0.007530643229854106\n",
      "Epoch: 172 Loss function: 0.007510807248396115\n",
      "Epoch: 173 Loss function: 0.007491211988080132\n",
      "Epoch: 174 Loss function: 0.0074718217150414835\n",
      "Epoch: 175 Loss function: 0.007452646443514216\n",
      "Epoch: 176 Loss function: 0.007433676673265281\n",
      "Epoch: 177 Loss function: 0.007414916475564655\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 178 Loss function: 0.007396360242937031\n",
      "Epoch: 179 Loss function: 0.007377994695193564\n",
      "Epoch: 180 Loss function: 0.007359823419536377\n",
      "Epoch: 181 Loss function: 0.007341842936325674\n",
      "Epoch: 182 Loss function: 0.00732405596144579\n",
      "Epoch: 183 Loss function: 0.007306453984676463\n",
      "Epoch: 184 Loss function: 0.007289025756183849\n",
      "Epoch: 185 Loss function: 0.00727176327089807\n",
      "Epoch: 186 Loss function: 0.007254682096601477\n",
      "Epoch: 187 Loss function: 0.007237770804355154\n",
      "Epoch: 188 Loss function: 0.007221015378513183\n",
      "Epoch: 189 Loss function: 0.007204436930080013\n",
      "Epoch: 190 Loss function: 0.00718801531471752\n",
      "Epoch: 191 Loss function: 0.007171754262903398\n",
      "Epoch: 192 Loss function: 0.00715563446038268\n",
      "Epoch: 193 Loss function: 0.007139670184677349\n",
      "Epoch: 194 Loss function: 0.007123862764683457\n",
      "Epoch: 195 Loss function: 0.007108194632265781\n",
      "Epoch: 196 Loss function: 0.0070926693262485544\n",
      "Epoch: 197 Loss function: 0.00707729809111665\n",
      "Epoch: 198 Loss function: 0.007062056390607358\n",
      "Epoch: 199 Loss function: 0.007046961735616704\n",
      "Epoch: 200 Loss function: 0.007031991063486298\n",
      "Epoch: 201 Loss function: 0.007017156822838121\n",
      "Epoch: 202 Loss function: 0.007002458394363874\n",
      "Epoch: 203 Loss function: 0.006987884069563658\n",
      "Epoch: 204 Loss function: 0.006973429815704044\n",
      "Epoch: 205 Loss function: 0.006959099727358274\n",
      "Epoch: 206 Loss function: 0.006944900021802075\n",
      "Epoch: 207 Loss function: 0.006930818028030132\n",
      "Epoch: 208 Loss function: 0.006916852989637316\n",
      "Epoch: 209 Loss function: 0.006903007713951094\n",
      "Epoch: 210 Loss function: 0.0068892769955294\n",
      "Epoch: 211 Loss function: 0.00687565188642369\n",
      "Epoch: 212 Loss function: 0.00686214395653368\n",
      "Epoch: 213 Loss function: 0.006848749580179227\n",
      "Epoch: 214 Loss function: 0.006835464992492039\n",
      "Epoch: 215 Loss function: 0.006822278021708285\n",
      "Epoch: 216 Loss function: 0.006809205354355784\n",
      "Epoch: 217 Loss function: 0.006796228218988622\n",
      "Epoch: 218 Loss function: 0.006783364836675469\n",
      "Epoch: 219 Loss function: 0.006770595532605915\n",
      "Epoch: 220 Loss function: 0.006757927974765229\n",
      "Epoch: 221 Loss function: 0.0067453572453211345\n",
      "Epoch: 222 Loss function: 0.006732875850453604\n",
      "Epoch: 223 Loss function: 0.0067204976052853745\n",
      "Epoch: 224 Loss function: 0.006708206417860925\n",
      "Epoch: 225 Loss function: 0.0066960200476354256\n",
      "Epoch: 226 Loss function: 0.00668391781641303\n",
      "Epoch: 227 Loss function: 0.0066719032132897885\n",
      "Epoch: 228 Loss function: 0.0066599843007846705\n",
      "Epoch: 229 Loss function: 0.006648148793565805\n",
      "Epoch: 230 Loss function: 0.006636399966817771\n",
      "Epoch: 231 Loss function: 0.006624737646397184\n",
      "Epoch: 232 Loss function: 0.006613158489615886\n",
      "Epoch: 233 Loss function: 0.0066016608987355075\n",
      "Epoch: 234 Loss function: 0.006590252041779476\n",
      "Epoch: 235 Loss function: 0.00657891982501136\n",
      "Epoch: 236 Loss function: 0.0065676684328116\n",
      "Epoch: 237 Loss function: 0.006556500604722763\n",
      "Epoch: 238 Loss function: 0.006545407256293968\n",
      "Epoch: 239 Loss function: 0.0065343922431159345\n",
      "Epoch: 240 Loss function: 0.006523451334382963\n",
      "Epoch: 241 Loss function: 0.00651259346696022\n",
      "Epoch: 242 Loss function: 0.006501805855677775\n",
      "Epoch: 243 Loss function: 0.006491089410127188\n",
      "Epoch: 244 Loss function: 0.006480447059160582\n",
      "Epoch: 245 Loss function: 0.00646987178589732\n",
      "Epoch: 246 Loss function: 0.006459378265836304\n",
      "Epoch: 247 Loss function: 0.006448949364783005\n",
      "Epoch: 248 Loss function: 0.006438588942305373\n",
      "Epoch: 249 Loss function: 0.00642830355446909\n",
      "Epoch: 250 Loss function: 0.006418087672888513\n",
      "Epoch: 251 Loss function: 0.00640794387673317\n",
      "Epoch: 252 Loss function: 0.006397859056657634\n",
      "Epoch: 253 Loss function: 0.006387843828306103\n",
      "Epoch: 254 Loss function: 0.006377892825360774\n",
      "Epoch: 255 Loss function: 0.006367999816997998\n",
      "Epoch: 256 Loss function: 0.006358172904960144\n",
      "Epoch: 257 Loss function: 0.0063484138504967995\n",
      "Epoch: 258 Loss function: 0.006338712991139675\n",
      "Epoch: 259 Loss function: 0.006329074289235273\n",
      "Epoch: 260 Loss function: 0.006319501062822452\n",
      "Epoch: 261 Loss function: 0.006309982845209122\n",
      "Epoch: 262 Loss function: 0.006300531923728538\n",
      "Epoch: 263 Loss function: 0.006291136320724569\n",
      "Epoch: 264 Loss function: 0.006281799925051697\n",
      "Epoch: 265 Loss function: 0.006272520977398231\n",
      "Epoch: 266 Loss function: 0.006263301981525105\n",
      "Epoch: 267 Loss function: 0.006254142576055851\n",
      "Epoch: 268 Loss function: 0.006245042040977628\n",
      "Epoch: 269 Loss function: 0.006235990225388313\n",
      "Epoch: 270 Loss function: 0.006227001515966937\n",
      "Epoch: 271 Loss function: 0.006218063451095611\n",
      "Epoch: 272 Loss function: 0.0062091796186920815\n",
      "Epoch: 273 Loss function: 0.006200346570759923\n",
      "Epoch: 274 Loss function: 0.0061915702756810955\n",
      "Epoch: 275 Loss function: 0.006182845558246417\n",
      "Epoch: 276 Loss function: 0.006174178025518385\n",
      "Epoch: 277 Loss function: 0.006165561982800034\n",
      "Epoch: 278 Loss function: 0.006156995498120188\n",
      "Epoch: 279 Loss function: 0.006148475091105505\n",
      "Epoch: 280 Loss function: 0.0061400138713459\n",
      "Epoch: 281 Loss function: 0.006131596253141607\n",
      "Epoch: 282 Loss function: 0.006123230278166121\n",
      "Epoch: 283 Loss function: 0.0061149141230950515\n",
      "Epoch: 284 Loss function: 0.006106652413572397\n",
      "Epoch: 285 Loss function: 0.006098432326279674\n",
      "Epoch: 286 Loss function: 0.006090269424821545\n",
      "Epoch: 287 Loss function: 0.006082152296052925\n",
      "Epoch: 288 Loss function: 0.006074082037931356\n",
      "Epoch: 289 Loss function: 0.006066057800789297\n",
      "Epoch: 290 Loss function: 0.006058080432929709\n",
      "Epoch: 291 Loss function: 0.006050144537434221\n",
      "Epoch: 292 Loss function: 0.006042257201179225\n",
      "Epoch: 293 Loss function: 0.006034411663536519\n",
      "Epoch: 294 Loss function: 0.006026608736455783\n",
      "Epoch: 295 Loss function: 0.006018858182189862\n",
      "Epoch: 296 Loss function: 0.006011152443755401\n",
      "Epoch: 297 Loss function: 0.006003489674172721\n",
      "Epoch: 298 Loss function: 0.00599587198806798\n",
      "Epoch: 299 Loss function: 0.00598829407945515\n",
      "Epoch: 300 Loss function: 0.005980763578420948\n",
      "Epoch: 301 Loss function: 0.005973268799175092\n",
      "Epoch: 302 Loss function: 0.005965816019680451\n",
      "Epoch: 303 Loss function: 0.005958412644186624\n",
      "Epoch: 304 Loss function: 0.0059510439999996365\n",
      "Epoch: 305 Loss function: 0.0059437204899274124\n",
      "Epoch: 306 Loss function: 0.005936436987677924\n",
      "Epoch: 307 Loss function: 0.005929192898966781\n",
      "Epoch: 308 Loss function: 0.005921985585879109\n",
      "Epoch: 309 Loss function: 0.005914822072204061\n",
      "Epoch: 310 Loss function: 0.005907697706874226\n",
      "Epoch: 311 Loss function: 0.005900614245956334\n",
      "Epoch: 312 Loss function: 0.00589357059706416\n",
      "Epoch: 313 Loss function: 0.005886563071137867\n",
      "Epoch: 314 Loss function: 0.005879601682311596\n",
      "Epoch: 315 Loss function: 0.005872670475921762\n",
      "Epoch: 316 Loss function: 0.005865775765086392\n",
      "Epoch: 317 Loss function: 0.005858926352513716\n",
      "Epoch: 318 Loss function: 0.005852115993138174\n",
      "Epoch: 319 Loss function: 0.0058453382430298595\n",
      "Epoch: 320 Loss function: 0.00583859924632233\n",
      "Epoch: 321 Loss function: 0.0058318927110194005\n",
      "Epoch: 322 Loss function: 0.005825228331864452\n",
      "Epoch: 323 Loss function: 0.0058185970733396365\n",
      "Epoch: 324 Loss function: 0.005812007777656744\n",
      "Epoch: 325 Loss function: 0.005805449862744054\n",
      "Epoch: 326 Loss function: 0.0057989287777102305\n",
      "Epoch: 327 Loss function: 0.005792442959841318\n",
      "Epoch: 328 Loss function: 0.0057859880004700135\n",
      "Epoch: 329 Loss function: 0.005779572431509431\n",
      "Epoch: 330 Loss function: 0.005773190111786904\n",
      "Epoch: 331 Loss function: 0.005766843236724753\n",
      "Epoch: 332 Loss function: 0.005760535786761213\n",
      "Epoch: 333 Loss function: 0.0057542531899469705\n",
      "Epoch: 334 Loss function: 0.005748006443116116\n",
      "Epoch: 335 Loss function: 0.005741794163717662\n",
      "Epoch: 336 Loss function: 0.005735611769216881\n",
      "Epoch: 337 Loss function: 0.005729468000826579\n",
      "Epoch: 338 Loss function: 0.005723351462963226\n",
      "Epoch: 339 Loss function: 0.005717272111411316\n",
      "Epoch: 340 Loss function: 0.005711224545844856\n",
      "Epoch: 341 Loss function: 0.005705209359670166\n",
      "Epoch: 342 Loss function: 0.005699230622585176\n",
      "Epoch: 343 Loss function: 0.005693278834134169\n",
      "Epoch: 344 Loss function: 0.005687357509939413\n",
      "Epoch: 345 Loss function: 0.005681471084604733\n",
      "Epoch: 346 Loss function: 0.005675611613762805\n",
      "Epoch: 347 Loss function: 0.005669787415192476\n",
      "Epoch: 348 Loss function: 0.0056639909911913745\n",
      "Epoch: 349 Loss function: 0.005658227665485895\n",
      "Epoch: 350 Loss function: 0.005652493656709595\n",
      "Epoch: 351 Loss function: 0.005646789213183414\n",
      "Epoch: 352 Loss function: 0.005641116560721383\n",
      "Epoch: 353 Loss function: 0.005635470743240592\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 354 Loss function: 0.005629858220783561\n",
      "Epoch: 355 Loss function: 0.005624272867169046\n",
      "Epoch: 356 Loss function: 0.005618719917646863\n",
      "Epoch: 357 Loss function: 0.005613189839031361\n",
      "Epoch: 358 Loss function: 0.005607694486955473\n",
      "Epoch: 359 Loss function: 0.005602225541630383\n",
      "Epoch: 360 Loss function: 0.005596788878432166\n",
      "Epoch: 361 Loss function: 0.005591376624677514\n",
      "Epoch: 362 Loss function: 0.005585989688216685\n",
      "Epoch: 363 Loss function: 0.005580632687854378\n",
      "Epoch: 364 Loss function: 0.005575300772323334"
     ]
    }
   ],
   "source": [
    "example1_trial_solution.train(Xe1, 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xe1plot = np.arange(0,1.2, 0.01)\n",
    "Xe1plot = Xe1plot.reshape((Xe1plot.shape[0], 1, 1))\n",
    "Ye1 = np.array([example1_trial_solution.predict(Xe1plot[i]) for i in range(Xe1plot.shape[0])]).reshape((Xe1plot.shape[0],))\n",
    "Xe1plot = Xe1plot.reshape((Xe1plot.shape[0],))\n",
    "Ye12 = np.array([np.exp(-0.5*Xe1plot[i]**2)/(1+Xe1plot[i]+Xe1plot[i]**3) + Xe1plot[i]**2 for i in range(Xe1plot.shape[0])])\n",
    "plt.scatter(Xe1plot, Ye1, c='g', label='Numerical')\n",
    "plt.plot(Xe1plot, Ye12, c='r', label='Analytic')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
