{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pixiedust database opened successfully\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style=\"margin:10px\">\n",
       "            <a href=\"https://github.com/ibm-watson-data-lab/pixiedust\" target=\"_new\">\n",
       "                <img src=\"https://github.com/ibm-watson-data-lab/pixiedust/raw/master/docs/_static/pd_icon32.png\" style=\"float:left;margin-right:10px\"/>\n",
       "            </a>\n",
       "            <span>Pixiedust version 1.1.15</span>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nnde\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "np.seterr(all='raise')\n",
    "import pixiedust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_samples = 10\n",
    "X_p = np.linspace(0, 1, n_samples)\n",
    "Y_p = np.linspace(0, 1, n_samples)\n",
    "X_p, Y_p = np.meshgrid(X_p, Y_p)\n",
    "X_p = X_p.flatten()\n",
    "Y_p = Y_p.flatten()\n",
    "samples = np.array([X_p, Y_p]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example A: 1d string with fixed ends\n",
    "\n",
    "$$\\frac{\\partial^2 u}{\\partial t^2}=c^2\\frac{\\partial^2 u}{\\partial x^2}$$\n",
    "\n",
    "With boundary conditions $u(0,t)=0$, $u(1, t)=0$, $u(x, 0)=\\sin(\\pi x$, and $\\frac{\\partial u}{\\partial t}(x, 0)=0$.\n",
    "\n",
    "The trial solution for this case is $u(x, y)=A(x, y) + B(x, y)(N(x, y)-N(x,0)-\\frac{\\partial N}{\\partial t}(x, 0))$ with $B(x)=x(1-x)t$ and $$A(x, y)=\\sin(\\pi x).$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def exampleA_boundary_value(point):\n",
    "  return np.sin(np.pi * point[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def exampleA_boundary_vanishing(point):\n",
    "  x = point[0]\n",
    "  t = point[1]\n",
    "  return x * (1 - x) * t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the loss function for a single point and a whole set\n",
    "\n",
    "The loss function is based on the formula:\n",
    "$$Loss(N)=\\sum_i \\left(\\frac{\\partial^2 u}{\\partial t^2}-c^2\\frac{\\partial^2 u}{\\partial x^2}\\right)^2$$\n",
    "And the Laplace operator term acting on the trial solution becomes:\n",
    "$$\\frac{\\partial^2 u}{\\partial t^2}-c^2\\frac{\\partial^2 u}{\\partial x^2}=\\frac{\\partial^2 A(x,y)}{\\partial t^2} -c^2 \\frac{\\partial^2 A(x,y)}{\\partial x^2}  + \\left(\\frac{\\partial^2}{\\partial t^2}-c^2 \\frac{\\partial^2}{\\partial x^2}\\right)(x(1-x)t\\left[N(x,t)-N(x,1)-\\dot{N}(x,1)\\right])$$\n",
    "$$=c^2\\pi^2\\sin(\\pi x) + 2x(1-x)\\dot{N}(x,t) + x(1-x)t\\ddot{N}(x,t) +2c^2t\\left[N(x,t)-N(x,1)-\\dot{N}(x,1)\\right]$$\n",
    "$$-2c^2(1-2x)t\\left[N'(x,t)-N'(x,1)-\\dot{N}'(x,1)\\right]  -c^2x(1-x)t\\left[N''(x,t)-N''(x,1)-\\dot{N}''(x,1)\\right]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def exampleA_loss_function_single_point(self, point, non_squared=False, *kwargs):\n",
    "  x = point[0][0] if isinstance(point[0], np.ndarray) else point[0]\n",
    "  t = point[1][0] if isinstance(point[1], np.ndarray) else point[0]\n",
    "  \n",
    "  N = self.forward_pass(point, 0)\n",
    "  dN = self.forward_pass(point, 1)\n",
    "  d2N = self.forward_pass(point, 2)\n",
    "  \n",
    "  N1 = self.forward_pass(np.array([x, 1]), 0)\n",
    "  dN1 = self.forward_pass(np.array([x, 1]), 1)\n",
    "  d2N1 = self.forward_pass(np.array([x, 1]), 2)\n",
    "  \n",
    "  dxdtN1 = self.forward_pass_arbitrary_derivative(np.array([x, 1]), np.array([1, 1]))\n",
    "  dx2dtN1 = self.forward_pass_arbitrary_derivative(np.array([x, 1]), np.array([2, 1]))\n",
    "  \n",
    "  loss = ( c**2*np.pi**2 *np.sin(np.pi * x) +2*x*(1-x)*dN[0, 1] + x*(1-x)*t*d2N[0, 1] +2*c**2*t*(N[0]-N1[0]-dN1[0, 1])\n",
    "          -2*c**2*t*(1-2*x)*(dN[0, 0] - dN1[0, 0] - dxdtN1[0]) -c**2*x*(1-x)*t*(d2N[0, 0] - d2N1[0, 0] - dx2dtN1[0])\n",
    "    )\n",
    "  if not non_squared:\n",
    "    loss = loss ** 2\n",
    "  return loss[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def exampleA_loss_function(self, samples, *kwargs):\n",
    "  loss = 0\n",
    "  for i in range(samples.shape[0]):\n",
    "    loss += self.loss_function_single_point(self, samples[i])\n",
    "  return loss/samples.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the update rules\n",
    "\n",
    "The following functions represent $\\frac{\\partial Loss}{\\partial \\vec{b}}$, $\\frac{\\partial Loss}{\\partial H}$, and $\\frac{\\partial Loss}{\\partial V}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def exampleA_bias_change(self, point, label, *kwargs):\n",
    "  x = point[0][0] if isinstance(point[0], np.ndarray) else point[0]\n",
    "  t = point[1][0] if isinstance(point[1], np.ndarray) else point[0]\n",
    "  \n",
    "  db_N = self.network_derivative_bias(point, 0)\n",
    "  db_DN = self.network_derivative_bias(point, 1)\n",
    "  db_D2N = self.network_derivative_bias(point, 2)\n",
    "  \n",
    "  db_N1 = self.network_derivative_bias(np.array([x, 1]), 0)\n",
    "  db_DN1 = self.network_derivative_bias(np.array([x, 1]), 1)\n",
    "  db_D2N1 = self.network_derivative_bias(np.array([x, 1]), 2)\n",
    "  \n",
    "  db_dxdtN1 = self.arbitrary_network_derivative_bias(np.array([x, 1]), np.array([1, 1]))\n",
    "  db_dx2dtN1 = self.arbitrary_network_derivative_bias(np.array([x, 1]), np.array([2, 1]))\n",
    "\n",
    "  db = np.zeros((self.hidden_dim, 1)).astype(dtype=\"float64\")\n",
    "  loss_sqrt = self.loss_function_single_point(self, point, non_squared=True)\n",
    "  \n",
    "  for m in range(self.hidden_dim):\n",
    "    db[m] += 2 * loss_sqrt * ( \n",
    "      2*x*(1-x)*db_DN[0, 1, m] + x*(1-x)*t*db_D2N[0, 1, m] +2*c**2*t*(db_N[0, 0, m]-db_N1[0, 0, m]-db_DN1[0, 1, m])\n",
    "          -2*c**2*t*(1-2*x)*(db_DN[0, 0, m] - db_DN1[0, 0, m] - db_dxdtN1[0, m]) -c**2*x*(1-x)*t*(db_D2N[0, 0, m]\n",
    "          - db_D2N1[0, 0, m] - db_dx2dtN1[0, m])\n",
    "      )\n",
    "  return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def exampleA_hidden_weights_change(self, point, *kwargs):\n",
    "  x = point[0][0] if isinstance(point[0], np.ndarray) else point[0]\n",
    "  t = point[1][0] if isinstance(point[1], np.ndarray) else point[0]\n",
    "  \n",
    "  dH_N = self.network_derivative_hidden_weights(point, 0)\n",
    "  dH_DN = self.network_derivative_hidden_weights(point, 1)\n",
    "  dH_D2N = self.network_derivative_hidden_weights(point, 2)\n",
    "  \n",
    "  dH_N1 = self.network_derivative_hidden_weights(np.array([x, 1]), 0)\n",
    "  dH_DN1 = self.network_derivative_hidden_weights(np.array([x, 1]), 1)\n",
    "  dH_D2N1 = self.network_derivative_hidden_weights(np.array([x, 1]), 2)\n",
    "  \n",
    "  dH_dxdtN1 = self.arbitrary_network_derivative_hidden_weights(np.array([x, 1]), np.array([1, 1]))\n",
    "  dH_dx2dtN1 = self.arbitrary_network_derivative_hidden_weights(np.array([x, 1]), np.array([2, 1]))\n",
    "\n",
    "  dH = np.zeros((self.hidden_dim, self.input_dim)).astype(dtype=\"float64\")\n",
    "  loss_sqrt = self.loss_function_single_point(self, point, non_squared=True)\n",
    "  for m in range(self.hidden_dim):\n",
    "    for p in range(self.input_dim):\n",
    "      dH[m, p] += 2 * loss_sqrt * ( \n",
    "      2*x*(1-x)*dH_DN[0, 1, m, p] + x*(1-x)*t*dH_D2N[0, 1, m, p] +2*c**2*t*(dH_N[0, 0, m, p]-dH_N1[0, 0, m, p]-dH_DN1[0, 1, m, p])\n",
    "          -2*c**2*t*(1-2*x)*(dH_DN[0, 0, m, p] - dH_DN1[0, 0, m, p] - dH_dxdtN1[0, m, p]) -c**2*x*(1-x)*t*(dH_D2N[0, 0, m, p]\n",
    "          - dH_D2N1[0, 0, m, p] - dH_dx2dtN1[0, m, p])\n",
    "      )\n",
    "  return dH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def exampleA_visible_weights_change(self, point, *kwargs):\n",
    "  x = point[0][0] if isinstance(point[0], np.ndarray) else point[0]\n",
    "  t = point[1][0] if isinstance(point[1], np.ndarray) else point[0]\n",
    "  \n",
    "  dV_N = self.network_derivative_visible_weights(point, 0)\n",
    "  dV_DN = self.network_derivative_visible_weights(point, 1)\n",
    "  dV_D2N = self.network_derivative_visible_weights(point, 2)\n",
    "  \n",
    "  dV_N1 = self.network_derivative_visible_weights(np.array([x, 1]), 0)\n",
    "  dV_DN1 = self.network_derivative_visible_weights(np.array([x, 1]), 1)\n",
    "  dV_D2N1 = self.network_derivative_visible_weights(np.array([x, 1]), 2)\n",
    "  \n",
    "  dV_dxdtN1 = self.arbitrary_network_derivative_visible_weights(np.array([x, 1]), np.array([1, 1]))\n",
    "  dV_dx2dtN1 = self.arbitrary_network_derivative_visible_weights(np.array([x, 1]), np.array([2, 1]))\n",
    "\n",
    "  dV = np.zeros((self.visible_dim, self.hidden_dim)).astype(dtype=\"float64\")\n",
    "  loss_sqrt = self.loss_function_single_point(self, point, non_squared=True)\n",
    "  for m in range(self.visible_dim):\n",
    "    for p in range(self.hidden_dim):\n",
    "      dV[m, p] += 2 * loss_sqrt * ( \n",
    "      2*x*(1-x)*dV_DN[0, 1, m, p] + x*(1-x)*t*dV_D2N[0, 1, m, p] +2*c**2*t*(dV_N[0, 0, m, p]-dV_N1[0, 0, m, p]-dV_DN1[0, 1, m, p])\n",
    "          -2*c**2*t*(1-2*x)*(dV_DN[0, 0, m, p] - dV_DN1[0, 0, m, p] - dV_dxdtN1[0, m, p]) -c**2*x*(1-x)*t*(dV_D2N[0, 0, m, p]\n",
    "          - dV_D2N1[0, 0, m, p] - dV_dx2dtN1[0, m, p])\n",
    "      )\n",
    "  return dV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the trial solution with an apropiate network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "exampleA_trial_solution = nnde.TrialSolution(loss_function=exampleA_loss_function,\n",
    "                                        loss_function_single_point=exampleA_loss_function_single_point,\n",
    "                                        bias_change=exampleA_bias_change,\n",
    "                                        hidden_weights_change=exampleA_hidden_weights_change,\n",
    "                                        visible_weights_change=exampleA_visible_weights_change,\n",
    "                                        boundary_condition_value_function=exampleA_boundary_value,\n",
    "                                        boundary_vanishing_function=exampleA_boundary_vanishing,\n",
    "                                        input_dim=2, hidden_dim=10, output_dim=1, learning_rate=0.01, momentum=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training for 5000 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "FloatingPointError",
     "evalue": "overflow encountered in exp",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFloatingPointError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-a6c0f4454a29>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mexampleA_trial_solution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/GitHub/NNDE/trialsolution.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, samples, epochs)\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;36m2.\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mpositive\u001b[0m \u001b[0minteger\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msecured\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mShallowNetwork\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mtraining\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber\u001b[0m \u001b[0mof\u001b[0m \u001b[0mtraining\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         '''\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/GitHub/NNDE/shallownetwork.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, samples, epochs, labels, verbose)\u001b[0m\n\u001b[1;32m    482\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 484\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msingle_epoch_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    485\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msingle_epoch_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/NNDE/shallownetwork.py\u001b[0m in \u001b[0;36msingle_epoch_training\u001b[0;34m(self, X, labels)\u001b[0m\n\u001b[1;32m    422\u001b[0m             \u001b[0;31m# --------------------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m             \u001b[0;31m# Bias change for given point\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m             \u001b[0mcurr_bias_change\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias_change\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m             \u001b[0;31m# --------------------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m             \u001b[0;31m# Hidden weights change for the given point\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-1de715708127>\u001b[0m in \u001b[0;36mexampleA_bias_change\u001b[0;34m(self, point, label, *kwargs)\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0mdb_N\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetwork_derivative_bias\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m   \u001b[0mdb_DN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetwork_derivative_bias\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mdb_D2N\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetwork_derivative_bias\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/NNDE/shallownetwork.py\u001b[0m in \u001b[0;36mnetwork_derivative_bias\u001b[0;34m(self, point, n)\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             hidden_activation_deriv_np1 = self.hidden_layer.activation_function(self.hidden_layer.linear_response(\n\u001b[0;32m--> 298\u001b[0;31m                 point), n+1)\n\u001b[0m\u001b[1;32m    299\u001b[0m             db_DnN = np.zeros(\n\u001b[1;32m    300\u001b[0m                 (self.visible_dim, self.input_dim, self.hidden_dim))\n",
      "\u001b[0;32m~/Documents/GitHub/NNDE/utilities.py\u001b[0m in \u001b[0;36msigmoid\u001b[0;34m(x, n)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mreturns\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     '''\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mtemp_sig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"float128\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mtemp_sig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtemp_sig\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFloatingPointError\u001b[0m: overflow encountered in exp"
     ]
    }
   ],
   "source": [
    "exampleA_trial_solution.train(samples, int(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the results \n",
    "\n",
    "The numerical solution (training set - red, valdiaiton set - green) along with the analytical solution (blue)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "new_shape = int(np.sqrt(samples.shape[0]))\n",
    "ZeAsol = np.array([exampleA_trial_solution.predict(samples[i]) for i in range(samples.shape[0])]).reshape((samples.shape[0],))\n",
    "ax.plot_surface(X=samples[:,0].reshape((new_shape, new_shape)), Y=samples[:,1].reshape((new_shape, new_shape)), Z=ZeAsol.reshape((new_shape, new_shape)), label='Numerical - Training')\n",
    "# ax.scatter3D(xs=samples[:,0], ys=samples[:,1], zs=ZeAsol, label='Numerical - Training')\n",
    "# plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ZeAanal = (samples[:,0] + samples[:,1]**3) * np.exp(-samples[:, 0])\n",
    "ZeAdiff = ZeAsol - ZeAanal\n",
    "ax.plot_surface(X=samples[:,0].reshape((new_shape, new_shape)), Y=samples[:,1].reshape((new_shape, new_shape)), Z=ZeAanal.reshape((new_shape, new_shape)), label='Analytic')\n",
    "# plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ZeAdiff.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
